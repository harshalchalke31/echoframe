{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision.models import mobilenet_v3_large,mobilenet_v3_small\n",
    "from utils import get_config\n",
    "from modelv5 import MobileNetV3UNet as MobileNetV3UNetv5\n",
    "from modelv6 import MobileNetV3UNet as MobileNetV3UNetv6\n",
    "from modelv7 import MobileNetV3UNet as MobileNetV3UNetv7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hc4293/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hc4293/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3UNet(\n",
      "  (encoder): MobileNetV3Encoder(\n",
      "    (backbone_model): MobileNetV3(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "              (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (12): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (13): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (14): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (15): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (16): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (classifier): Sequential(\n",
      "        (0): Linear(in_features=960, out_features=1280, bias=True)\n",
      "        (1): Hardswish()\n",
      "        (2): Dropout(p=0.2, inplace=True)\n",
      "        (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): UpsampleBlock(\n",
      "      (conv1): Conv2d(1000, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): UpsampleBlock(\n",
      "      (conv1): Conv2d(44, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): UpsampleBlock(\n",
      "      (conv1): Conv2d(40, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): UpsampleBlock(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (final_upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "  (seg_head): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 56, 56]             576\n",
      "       BatchNorm2d-2           [-1, 16, 56, 56]              32\n",
      "         Hardswish-3           [-1, 16, 56, 56]               0\n",
      "            Conv2d-4           [-1, 16, 56, 56]             144\n",
      "       BatchNorm2d-5           [-1, 16, 56, 56]              32\n",
      "              ReLU-6           [-1, 16, 56, 56]               0\n",
      "            Conv2d-7           [-1, 16, 56, 56]             256\n",
      "       BatchNorm2d-8           [-1, 16, 56, 56]              32\n",
      "  InvertedResidual-9           [-1, 16, 56, 56]               0\n",
      "           Conv2d-10           [-1, 64, 56, 56]           1,024\n",
      "      BatchNorm2d-11           [-1, 64, 56, 56]             128\n",
      "             ReLU-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 28, 28]             576\n",
      "      BatchNorm2d-14           [-1, 64, 28, 28]             128\n",
      "             ReLU-15           [-1, 64, 28, 28]               0\n",
      "           Conv2d-16           [-1, 24, 28, 28]           1,536\n",
      "      BatchNorm2d-17           [-1, 24, 28, 28]              48\n",
      " InvertedResidual-18           [-1, 24, 28, 28]               0\n",
      "           Conv2d-19           [-1, 72, 28, 28]           1,728\n",
      "      BatchNorm2d-20           [-1, 72, 28, 28]             144\n",
      "             ReLU-21           [-1, 72, 28, 28]               0\n",
      "           Conv2d-22           [-1, 72, 28, 28]             648\n",
      "      BatchNorm2d-23           [-1, 72, 28, 28]             144\n",
      "             ReLU-24           [-1, 72, 28, 28]               0\n",
      "           Conv2d-25           [-1, 24, 28, 28]           1,728\n",
      "      BatchNorm2d-26           [-1, 24, 28, 28]              48\n",
      " InvertedResidual-27           [-1, 24, 28, 28]               0\n",
      "           Conv2d-28           [-1, 72, 28, 28]           1,728\n",
      "      BatchNorm2d-29           [-1, 72, 28, 28]             144\n",
      "             ReLU-30           [-1, 72, 28, 28]               0\n",
      "           Conv2d-31           [-1, 72, 14, 14]           1,800\n",
      "      BatchNorm2d-32           [-1, 72, 14, 14]             144\n",
      "             ReLU-33           [-1, 72, 14, 14]               0\n",
      "AdaptiveAvgPool2d-34             [-1, 72, 1, 1]               0\n",
      "           Conv2d-35             [-1, 24, 1, 1]           1,752\n",
      "             ReLU-36             [-1, 24, 1, 1]               0\n",
      "           Conv2d-37             [-1, 72, 1, 1]           1,800\n",
      "      Hardsigmoid-38             [-1, 72, 1, 1]               0\n",
      "SqueezeExcitation-39           [-1, 72, 14, 14]               0\n",
      "           Conv2d-40           [-1, 40, 14, 14]           2,880\n",
      "      BatchNorm2d-41           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-42           [-1, 40, 14, 14]               0\n",
      "           Conv2d-43          [-1, 120, 14, 14]           4,800\n",
      "      BatchNorm2d-44          [-1, 120, 14, 14]             240\n",
      "             ReLU-45          [-1, 120, 14, 14]               0\n",
      "           Conv2d-46          [-1, 120, 14, 14]           3,000\n",
      "      BatchNorm2d-47          [-1, 120, 14, 14]             240\n",
      "             ReLU-48          [-1, 120, 14, 14]               0\n",
      "AdaptiveAvgPool2d-49            [-1, 120, 1, 1]               0\n",
      "           Conv2d-50             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-51             [-1, 32, 1, 1]               0\n",
      "           Conv2d-52            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-53            [-1, 120, 1, 1]               0\n",
      "SqueezeExcitation-54          [-1, 120, 14, 14]               0\n",
      "           Conv2d-55           [-1, 40, 14, 14]           4,800\n",
      "      BatchNorm2d-56           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-57           [-1, 40, 14, 14]               0\n",
      "           Conv2d-58          [-1, 120, 14, 14]           4,800\n",
      "      BatchNorm2d-59          [-1, 120, 14, 14]             240\n",
      "             ReLU-60          [-1, 120, 14, 14]               0\n",
      "           Conv2d-61          [-1, 120, 14, 14]           3,000\n",
      "      BatchNorm2d-62          [-1, 120, 14, 14]             240\n",
      "             ReLU-63          [-1, 120, 14, 14]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 120, 1, 1]               0\n",
      "           Conv2d-65             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-66             [-1, 32, 1, 1]               0\n",
      "           Conv2d-67            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-68            [-1, 120, 1, 1]               0\n",
      "SqueezeExcitation-69          [-1, 120, 14, 14]               0\n",
      "           Conv2d-70           [-1, 40, 14, 14]           4,800\n",
      "      BatchNorm2d-71           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-72           [-1, 40, 14, 14]               0\n",
      "           Conv2d-73          [-1, 240, 14, 14]           9,600\n",
      "      BatchNorm2d-74          [-1, 240, 14, 14]             480\n",
      "        Hardswish-75          [-1, 240, 14, 14]               0\n",
      "           Conv2d-76            [-1, 240, 7, 7]           2,160\n",
      "      BatchNorm2d-77            [-1, 240, 7, 7]             480\n",
      "        Hardswish-78            [-1, 240, 7, 7]               0\n",
      "           Conv2d-79             [-1, 80, 7, 7]          19,200\n",
      "      BatchNorm2d-80             [-1, 80, 7, 7]             160\n",
      " InvertedResidual-81             [-1, 80, 7, 7]               0\n",
      "           Conv2d-82            [-1, 200, 7, 7]          16,000\n",
      "      BatchNorm2d-83            [-1, 200, 7, 7]             400\n",
      "        Hardswish-84            [-1, 200, 7, 7]               0\n",
      "           Conv2d-85            [-1, 200, 7, 7]           1,800\n",
      "      BatchNorm2d-86            [-1, 200, 7, 7]             400\n",
      "        Hardswish-87            [-1, 200, 7, 7]               0\n",
      "           Conv2d-88             [-1, 80, 7, 7]          16,000\n",
      "      BatchNorm2d-89             [-1, 80, 7, 7]             160\n",
      " InvertedResidual-90             [-1, 80, 7, 7]               0\n",
      "           Conv2d-91            [-1, 184, 7, 7]          14,720\n",
      "      BatchNorm2d-92            [-1, 184, 7, 7]             368\n",
      "        Hardswish-93            [-1, 184, 7, 7]               0\n",
      "           Conv2d-94            [-1, 184, 7, 7]           1,656\n",
      "      BatchNorm2d-95            [-1, 184, 7, 7]             368\n",
      "        Hardswish-96            [-1, 184, 7, 7]               0\n",
      "           Conv2d-97             [-1, 80, 7, 7]          14,720\n",
      "      BatchNorm2d-98             [-1, 80, 7, 7]             160\n",
      " InvertedResidual-99             [-1, 80, 7, 7]               0\n",
      "          Conv2d-100            [-1, 184, 7, 7]          14,720\n",
      "     BatchNorm2d-101            [-1, 184, 7, 7]             368\n",
      "       Hardswish-102            [-1, 184, 7, 7]               0\n",
      "          Conv2d-103            [-1, 184, 7, 7]           1,656\n",
      "     BatchNorm2d-104            [-1, 184, 7, 7]             368\n",
      "       Hardswish-105            [-1, 184, 7, 7]               0\n",
      "          Conv2d-106             [-1, 80, 7, 7]          14,720\n",
      "     BatchNorm2d-107             [-1, 80, 7, 7]             160\n",
      "InvertedResidual-108             [-1, 80, 7, 7]               0\n",
      "          Conv2d-109            [-1, 480, 7, 7]          38,400\n",
      "     BatchNorm2d-110            [-1, 480, 7, 7]             960\n",
      "       Hardswish-111            [-1, 480, 7, 7]               0\n",
      "          Conv2d-112            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-113            [-1, 480, 7, 7]             960\n",
      "       Hardswish-114            [-1, 480, 7, 7]               0\n",
      "AdaptiveAvgPool2d-115            [-1, 480, 1, 1]               0\n",
      "          Conv2d-116            [-1, 120, 1, 1]          57,720\n",
      "            ReLU-117            [-1, 120, 1, 1]               0\n",
      "          Conv2d-118            [-1, 480, 1, 1]          58,080\n",
      "     Hardsigmoid-119            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-120            [-1, 480, 7, 7]               0\n",
      "          Conv2d-121            [-1, 112, 7, 7]          53,760\n",
      "     BatchNorm2d-122            [-1, 112, 7, 7]             224\n",
      "InvertedResidual-123            [-1, 112, 7, 7]               0\n",
      "          Conv2d-124            [-1, 672, 7, 7]          75,264\n",
      "     BatchNorm2d-125            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-126            [-1, 672, 7, 7]               0\n",
      "          Conv2d-127            [-1, 672, 7, 7]           6,048\n",
      "     BatchNorm2d-128            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-129            [-1, 672, 7, 7]               0\n",
      "AdaptiveAvgPool2d-130            [-1, 672, 1, 1]               0\n",
      "          Conv2d-131            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-132            [-1, 168, 1, 1]               0\n",
      "          Conv2d-133            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-134            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-135            [-1, 672, 7, 7]               0\n",
      "          Conv2d-136            [-1, 112, 7, 7]          75,264\n",
      "     BatchNorm2d-137            [-1, 112, 7, 7]             224\n",
      "InvertedResidual-138            [-1, 112, 7, 7]               0\n",
      "          Conv2d-139            [-1, 672, 7, 7]          75,264\n",
      "     BatchNorm2d-140            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-141            [-1, 672, 7, 7]               0\n",
      "          Conv2d-142            [-1, 672, 4, 4]          16,800\n",
      "     BatchNorm2d-143            [-1, 672, 4, 4]           1,344\n",
      "       Hardswish-144            [-1, 672, 4, 4]               0\n",
      "AdaptiveAvgPool2d-145            [-1, 672, 1, 1]               0\n",
      "          Conv2d-146            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-147            [-1, 168, 1, 1]               0\n",
      "          Conv2d-148            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-149            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-150            [-1, 672, 4, 4]               0\n",
      "          Conv2d-151            [-1, 160, 4, 4]         107,520\n",
      "     BatchNorm2d-152            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-153            [-1, 160, 4, 4]               0\n",
      "          Conv2d-154            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-155            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-156            [-1, 960, 4, 4]               0\n",
      "          Conv2d-157            [-1, 960, 4, 4]          24,000\n",
      "     BatchNorm2d-158            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-159            [-1, 960, 4, 4]               0\n",
      "AdaptiveAvgPool2d-160            [-1, 960, 1, 1]               0\n",
      "          Conv2d-161            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-162            [-1, 240, 1, 1]               0\n",
      "          Conv2d-163            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-164            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-165            [-1, 960, 4, 4]               0\n",
      "          Conv2d-166            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-167            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-168            [-1, 160, 4, 4]               0\n",
      "          Conv2d-169            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-170            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-171            [-1, 960, 4, 4]               0\n",
      "          Conv2d-172            [-1, 960, 4, 4]          24,000\n",
      "     BatchNorm2d-173            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-174            [-1, 960, 4, 4]               0\n",
      "AdaptiveAvgPool2d-175            [-1, 960, 1, 1]               0\n",
      "          Conv2d-176            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-177            [-1, 240, 1, 1]               0\n",
      "          Conv2d-178            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-179            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-180            [-1, 960, 4, 4]               0\n",
      "          Conv2d-181            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-182            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-183            [-1, 160, 4, 4]               0\n",
      "          Conv2d-184            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-185            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-186            [-1, 960, 4, 4]               0\n",
      "MobileNetV3Encoder-187  [[-1, 16, 56, 56], [-1, 24, 28, 28], [-1, 24, 28, 28], [-1, 40, 14, 14], [-1, 960, 4, 4]]               0\n",
      "          Conv2d-188           [-1, 20, 14, 14]         180,020\n",
      "     BatchNorm2d-189           [-1, 20, 14, 14]              40\n",
      "          Conv2d-190           [-1, 20, 14, 14]           3,620\n",
      "     BatchNorm2d-191           [-1, 20, 14, 14]              40\n",
      "   UpsampleBlock-192           [-1, 20, 14, 14]               0\n",
      "          Conv2d-193           [-1, 16, 28, 28]           6,352\n",
      "     BatchNorm2d-194           [-1, 16, 28, 28]              32\n",
      "          Conv2d-195           [-1, 16, 28, 28]           2,320\n",
      "     BatchNorm2d-196           [-1, 16, 28, 28]              32\n",
      "   UpsampleBlock-197           [-1, 16, 28, 28]               0\n",
      "          Conv2d-198           [-1, 16, 28, 28]           5,776\n",
      "     BatchNorm2d-199           [-1, 16, 28, 28]              32\n",
      "          Conv2d-200           [-1, 16, 28, 28]           2,320\n",
      "     BatchNorm2d-201           [-1, 16, 28, 28]              32\n",
      "   UpsampleBlock-202           [-1, 16, 28, 28]               0\n",
      "          Conv2d-203           [-1, 16, 56, 56]           4,624\n",
      "     BatchNorm2d-204           [-1, 16, 56, 56]              32\n",
      "          Conv2d-205           [-1, 16, 56, 56]           2,320\n",
      "     BatchNorm2d-206           [-1, 16, 56, 56]              32\n",
      "   UpsampleBlock-207           [-1, 16, 56, 56]               0\n",
      "        Upsample-208         [-1, 16, 112, 112]               0\n",
      "          Conv2d-209          [-1, 1, 112, 112]              17\n",
      "================================================================\n",
      "Total params: 3,179,737\n",
      "Trainable params: 3,179,737\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 4502321102816.34\n",
      "Params size (MB): 12.13\n",
      "Estimated Total Size (MB): 4502321102828.67\n",
      "----------------------------------------------------------------\n",
      "Output shape: torch.Size([1, 1, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Example: Now we can create a model with 4 channels input\n",
    "model = MobileNetV3UNetv5(in_channels=4, out_channels=1, config_name=\"large\", backbone=True).to(device)\n",
    "\n",
    "dummy_input = torch.randn(1, 4, 112, 112).to(device)\n",
    "print(model)\n",
    "summary(model, input_size=(4,112,112), device=str(device))\n",
    "output = model(dummy_input)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3UNet(\n",
      "  (mask_adapter): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (initial_image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (encoder): MobileNetV3Encoder(\n",
      "    (backbone_model): MobileNetV3(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "              (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (12): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (13): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (14): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (15): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (16): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (classifier): Identity()\n",
      "    )\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): UpsampleBlock(\n",
      "      (conv1): Conv2d(1000, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): UpsampleBlock(\n",
      "      (conv1): Conv2d(44, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): UpsampleBlock(\n",
      "      (conv1): Conv2d(40, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): UpsampleBlock(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (final_upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "  (seg_head): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 56, 56]             432\n",
      "       BatchNorm2d-2           [-1, 16, 56, 56]              32\n",
      "         Hardswish-3           [-1, 16, 56, 56]               0\n",
      "            Conv2d-4           [-1, 16, 56, 56]             144\n",
      "       BatchNorm2d-5           [-1, 16, 56, 56]              32\n",
      "              ReLU-6           [-1, 16, 56, 56]               0\n",
      "            Conv2d-7           [-1, 16, 56, 56]             144\n",
      "       BatchNorm2d-8           [-1, 16, 56, 56]              32\n",
      "              ReLU-9           [-1, 16, 56, 56]               0\n",
      "           Conv2d-10           [-1, 16, 56, 56]             256\n",
      "      BatchNorm2d-11           [-1, 16, 56, 56]              32\n",
      " InvertedResidual-12           [-1, 16, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]           1,024\n",
      "      BatchNorm2d-14           [-1, 64, 56, 56]             128\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 28, 28]             576\n",
      "      BatchNorm2d-17           [-1, 64, 28, 28]             128\n",
      "             ReLU-18           [-1, 64, 28, 28]               0\n",
      "           Conv2d-19           [-1, 24, 28, 28]           1,536\n",
      "      BatchNorm2d-20           [-1, 24, 28, 28]              48\n",
      " InvertedResidual-21           [-1, 24, 28, 28]               0\n",
      "           Conv2d-22           [-1, 72, 28, 28]           1,728\n",
      "      BatchNorm2d-23           [-1, 72, 28, 28]             144\n",
      "             ReLU-24           [-1, 72, 28, 28]               0\n",
      "           Conv2d-25           [-1, 72, 28, 28]             648\n",
      "      BatchNorm2d-26           [-1, 72, 28, 28]             144\n",
      "             ReLU-27           [-1, 72, 28, 28]               0\n",
      "           Conv2d-28           [-1, 24, 28, 28]           1,728\n",
      "      BatchNorm2d-29           [-1, 24, 28, 28]              48\n",
      " InvertedResidual-30           [-1, 24, 28, 28]               0\n",
      "           Conv2d-31           [-1, 72, 28, 28]           1,728\n",
      "      BatchNorm2d-32           [-1, 72, 28, 28]             144\n",
      "             ReLU-33           [-1, 72, 28, 28]               0\n",
      "           Conv2d-34           [-1, 72, 14, 14]           1,800\n",
      "      BatchNorm2d-35           [-1, 72, 14, 14]             144\n",
      "             ReLU-36           [-1, 72, 14, 14]               0\n",
      "AdaptiveAvgPool2d-37             [-1, 72, 1, 1]               0\n",
      "           Conv2d-38             [-1, 24, 1, 1]           1,752\n",
      "             ReLU-39             [-1, 24, 1, 1]               0\n",
      "           Conv2d-40             [-1, 72, 1, 1]           1,800\n",
      "      Hardsigmoid-41             [-1, 72, 1, 1]               0\n",
      "SqueezeExcitation-42           [-1, 72, 14, 14]               0\n",
      "           Conv2d-43           [-1, 40, 14, 14]           2,880\n",
      "      BatchNorm2d-44           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-45           [-1, 40, 14, 14]               0\n",
      "           Conv2d-46          [-1, 120, 14, 14]           4,800\n",
      "      BatchNorm2d-47          [-1, 120, 14, 14]             240\n",
      "             ReLU-48          [-1, 120, 14, 14]               0\n",
      "           Conv2d-49          [-1, 120, 14, 14]           3,000\n",
      "      BatchNorm2d-50          [-1, 120, 14, 14]             240\n",
      "             ReLU-51          [-1, 120, 14, 14]               0\n",
      "AdaptiveAvgPool2d-52            [-1, 120, 1, 1]               0\n",
      "           Conv2d-53             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-54             [-1, 32, 1, 1]               0\n",
      "           Conv2d-55            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-56            [-1, 120, 1, 1]               0\n",
      "SqueezeExcitation-57          [-1, 120, 14, 14]               0\n",
      "           Conv2d-58           [-1, 40, 14, 14]           4,800\n",
      "      BatchNorm2d-59           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-60           [-1, 40, 14, 14]               0\n",
      "           Conv2d-61          [-1, 120, 14, 14]           4,800\n",
      "      BatchNorm2d-62          [-1, 120, 14, 14]             240\n",
      "             ReLU-63          [-1, 120, 14, 14]               0\n",
      "           Conv2d-64          [-1, 120, 14, 14]           3,000\n",
      "      BatchNorm2d-65          [-1, 120, 14, 14]             240\n",
      "             ReLU-66          [-1, 120, 14, 14]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 120, 1, 1]               0\n",
      "           Conv2d-68             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-69             [-1, 32, 1, 1]               0\n",
      "           Conv2d-70            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-71            [-1, 120, 1, 1]               0\n",
      "SqueezeExcitation-72          [-1, 120, 14, 14]               0\n",
      "           Conv2d-73           [-1, 40, 14, 14]           4,800\n",
      "      BatchNorm2d-74           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-75           [-1, 40, 14, 14]               0\n",
      "           Conv2d-76          [-1, 240, 14, 14]           9,600\n",
      "      BatchNorm2d-77          [-1, 240, 14, 14]             480\n",
      "        Hardswish-78          [-1, 240, 14, 14]               0\n",
      "           Conv2d-79            [-1, 240, 7, 7]           2,160\n",
      "      BatchNorm2d-80            [-1, 240, 7, 7]             480\n",
      "        Hardswish-81            [-1, 240, 7, 7]               0\n",
      "           Conv2d-82             [-1, 80, 7, 7]          19,200\n",
      "      BatchNorm2d-83             [-1, 80, 7, 7]             160\n",
      " InvertedResidual-84             [-1, 80, 7, 7]               0\n",
      "           Conv2d-85            [-1, 200, 7, 7]          16,000\n",
      "      BatchNorm2d-86            [-1, 200, 7, 7]             400\n",
      "        Hardswish-87            [-1, 200, 7, 7]               0\n",
      "           Conv2d-88            [-1, 200, 7, 7]           1,800\n",
      "      BatchNorm2d-89            [-1, 200, 7, 7]             400\n",
      "        Hardswish-90            [-1, 200, 7, 7]               0\n",
      "           Conv2d-91             [-1, 80, 7, 7]          16,000\n",
      "      BatchNorm2d-92             [-1, 80, 7, 7]             160\n",
      " InvertedResidual-93             [-1, 80, 7, 7]               0\n",
      "           Conv2d-94            [-1, 184, 7, 7]          14,720\n",
      "      BatchNorm2d-95            [-1, 184, 7, 7]             368\n",
      "        Hardswish-96            [-1, 184, 7, 7]               0\n",
      "           Conv2d-97            [-1, 184, 7, 7]           1,656\n",
      "      BatchNorm2d-98            [-1, 184, 7, 7]             368\n",
      "        Hardswish-99            [-1, 184, 7, 7]               0\n",
      "          Conv2d-100             [-1, 80, 7, 7]          14,720\n",
      "     BatchNorm2d-101             [-1, 80, 7, 7]             160\n",
      "InvertedResidual-102             [-1, 80, 7, 7]               0\n",
      "          Conv2d-103            [-1, 184, 7, 7]          14,720\n",
      "     BatchNorm2d-104            [-1, 184, 7, 7]             368\n",
      "       Hardswish-105            [-1, 184, 7, 7]               0\n",
      "          Conv2d-106            [-1, 184, 7, 7]           1,656\n",
      "     BatchNorm2d-107            [-1, 184, 7, 7]             368\n",
      "       Hardswish-108            [-1, 184, 7, 7]               0\n",
      "          Conv2d-109             [-1, 80, 7, 7]          14,720\n",
      "     BatchNorm2d-110             [-1, 80, 7, 7]             160\n",
      "InvertedResidual-111             [-1, 80, 7, 7]               0\n",
      "          Conv2d-112            [-1, 480, 7, 7]          38,400\n",
      "     BatchNorm2d-113            [-1, 480, 7, 7]             960\n",
      "       Hardswish-114            [-1, 480, 7, 7]               0\n",
      "          Conv2d-115            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-116            [-1, 480, 7, 7]             960\n",
      "       Hardswish-117            [-1, 480, 7, 7]               0\n",
      "AdaptiveAvgPool2d-118            [-1, 480, 1, 1]               0\n",
      "          Conv2d-119            [-1, 120, 1, 1]          57,720\n",
      "            ReLU-120            [-1, 120, 1, 1]               0\n",
      "          Conv2d-121            [-1, 480, 1, 1]          58,080\n",
      "     Hardsigmoid-122            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-123            [-1, 480, 7, 7]               0\n",
      "          Conv2d-124            [-1, 112, 7, 7]          53,760\n",
      "     BatchNorm2d-125            [-1, 112, 7, 7]             224\n",
      "InvertedResidual-126            [-1, 112, 7, 7]               0\n",
      "          Conv2d-127            [-1, 672, 7, 7]          75,264\n",
      "     BatchNorm2d-128            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-129            [-1, 672, 7, 7]               0\n",
      "          Conv2d-130            [-1, 672, 7, 7]           6,048\n",
      "     BatchNorm2d-131            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-132            [-1, 672, 7, 7]               0\n",
      "AdaptiveAvgPool2d-133            [-1, 672, 1, 1]               0\n",
      "          Conv2d-134            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-135            [-1, 168, 1, 1]               0\n",
      "          Conv2d-136            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-137            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-138            [-1, 672, 7, 7]               0\n",
      "          Conv2d-139            [-1, 112, 7, 7]          75,264\n",
      "     BatchNorm2d-140            [-1, 112, 7, 7]             224\n",
      "InvertedResidual-141            [-1, 112, 7, 7]               0\n",
      "          Conv2d-142            [-1, 672, 7, 7]          75,264\n",
      "     BatchNorm2d-143            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-144            [-1, 672, 7, 7]               0\n",
      "          Conv2d-145            [-1, 672, 4, 4]          16,800\n",
      "     BatchNorm2d-146            [-1, 672, 4, 4]           1,344\n",
      "       Hardswish-147            [-1, 672, 4, 4]               0\n",
      "AdaptiveAvgPool2d-148            [-1, 672, 1, 1]               0\n",
      "          Conv2d-149            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-150            [-1, 168, 1, 1]               0\n",
      "          Conv2d-151            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-152            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-153            [-1, 672, 4, 4]               0\n",
      "          Conv2d-154            [-1, 160, 4, 4]         107,520\n",
      "     BatchNorm2d-155            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-156            [-1, 160, 4, 4]               0\n",
      "          Conv2d-157            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-158            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-159            [-1, 960, 4, 4]               0\n",
      "          Conv2d-160            [-1, 960, 4, 4]          24,000\n",
      "     BatchNorm2d-161            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-162            [-1, 960, 4, 4]               0\n",
      "AdaptiveAvgPool2d-163            [-1, 960, 1, 1]               0\n",
      "          Conv2d-164            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-165            [-1, 240, 1, 1]               0\n",
      "          Conv2d-166            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-167            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-168            [-1, 960, 4, 4]               0\n",
      "          Conv2d-169            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-170            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-171            [-1, 160, 4, 4]               0\n",
      "          Conv2d-172            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-173            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-174            [-1, 960, 4, 4]               0\n",
      "          Conv2d-175            [-1, 960, 4, 4]          24,000\n",
      "     BatchNorm2d-176            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-177            [-1, 960, 4, 4]               0\n",
      "AdaptiveAvgPool2d-178            [-1, 960, 1, 1]               0\n",
      "          Conv2d-179            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-180            [-1, 240, 1, 1]               0\n",
      "          Conv2d-181            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-182            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-183            [-1, 960, 4, 4]               0\n",
      "          Conv2d-184            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-185            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-186            [-1, 160, 4, 4]               0\n",
      "          Conv2d-187            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-188            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-189            [-1, 960, 4, 4]               0\n",
      "          Conv2d-190           [-1, 20, 14, 14]         180,020\n",
      "     BatchNorm2d-191           [-1, 20, 14, 14]              40\n",
      "          Conv2d-192           [-1, 20, 14, 14]           3,620\n",
      "     BatchNorm2d-193           [-1, 20, 14, 14]              40\n",
      "   UpsampleBlock-194           [-1, 20, 14, 14]               0\n",
      "          Conv2d-195           [-1, 16, 28, 28]           6,352\n",
      "     BatchNorm2d-196           [-1, 16, 28, 28]              32\n",
      "          Conv2d-197           [-1, 16, 28, 28]           2,320\n",
      "     BatchNorm2d-198           [-1, 16, 28, 28]              32\n",
      "   UpsampleBlock-199           [-1, 16, 28, 28]               0\n",
      "          Conv2d-200           [-1, 16, 28, 28]           5,776\n",
      "     BatchNorm2d-201           [-1, 16, 28, 28]              32\n",
      "          Conv2d-202           [-1, 16, 28, 28]           2,320\n",
      "     BatchNorm2d-203           [-1, 16, 28, 28]              32\n",
      "   UpsampleBlock-204           [-1, 16, 28, 28]               0\n",
      "          Conv2d-205           [-1, 16, 56, 56]           4,624\n",
      "     BatchNorm2d-206           [-1, 16, 56, 56]              32\n",
      "          Conv2d-207           [-1, 16, 56, 56]           2,320\n",
      "     BatchNorm2d-208           [-1, 16, 56, 56]              32\n",
      "   UpsampleBlock-209           [-1, 16, 56, 56]               0\n",
      "        Upsample-210         [-1, 16, 112, 112]               0\n",
      "          Conv2d-211          [-1, 1, 112, 112]              17\n",
      "================================================================\n",
      "Total params: 3,179,769\n",
      "Trainable params: 3,179,769\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 32.80\n",
      "Params size (MB): 12.13\n",
      "Estimated Total Size (MB): 45.13\n",
      "----------------------------------------------------------------\n",
      "Output shape: torch.Size([1, 1, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MobileNetV3UNetv6(in_channels=4, out_channels=1, backbone_pretrained=True).to(device)\n",
    "\n",
    "dummy_input = torch.randn(1, 4, 112, 112).to(device)\n",
    "output = model(dummy_input)\n",
    "print(model)\n",
    "summary(model, input_size=(4,112,112), device=str(device))\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hc4293/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hc4293/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3UNet(\n",
      "  (mask_adapter): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (initial_image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (encoder): MobileNetV3Encoder(\n",
      "    (backbone_model): MobileNetV3(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "              (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "              (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (12): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (13): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (14): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (15): InvertedResidual(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "              (2): Hardswish()\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): ReLU()\n",
      "              (scale_activation): Hardsigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (16): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (classifier): Identity()\n",
      "    )\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): UpsampleBlock(\n",
      "      (conv1): Conv2d(1000, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): UpsampleBlock(\n",
      "      (conv1): Conv2d(44, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): UpsampleBlock(\n",
      "      (conv1): Conv2d(40, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): UpsampleBlock(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (final_upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "  (seg_head): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 56, 56]             432\n",
      "       BatchNorm2d-2           [-1, 16, 56, 56]              32\n",
      "         Hardswish-3           [-1, 16, 56, 56]               0\n",
      "            Conv2d-4           [-1, 16, 56, 56]             144\n",
      "       BatchNorm2d-5           [-1, 16, 56, 56]              32\n",
      "              ReLU-6           [-1, 16, 56, 56]               0\n",
      "            Conv2d-7           [-1, 16, 56, 56]             144\n",
      "       BatchNorm2d-8           [-1, 16, 56, 56]              32\n",
      "              ReLU-9           [-1, 16, 56, 56]               0\n",
      "           Conv2d-10           [-1, 16, 56, 56]             256\n",
      "      BatchNorm2d-11           [-1, 16, 56, 56]              32\n",
      " InvertedResidual-12           [-1, 16, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]           1,024\n",
      "      BatchNorm2d-14           [-1, 64, 56, 56]             128\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 28, 28]             576\n",
      "      BatchNorm2d-17           [-1, 64, 28, 28]             128\n",
      "             ReLU-18           [-1, 64, 28, 28]               0\n",
      "           Conv2d-19           [-1, 24, 28, 28]           1,536\n",
      "      BatchNorm2d-20           [-1, 24, 28, 28]              48\n",
      " InvertedResidual-21           [-1, 24, 28, 28]               0\n",
      "           Conv2d-22           [-1, 72, 28, 28]           1,728\n",
      "      BatchNorm2d-23           [-1, 72, 28, 28]             144\n",
      "             ReLU-24           [-1, 72, 28, 28]               0\n",
      "           Conv2d-25           [-1, 72, 28, 28]             648\n",
      "      BatchNorm2d-26           [-1, 72, 28, 28]             144\n",
      "             ReLU-27           [-1, 72, 28, 28]               0\n",
      "           Conv2d-28           [-1, 24, 28, 28]           1,728\n",
      "      BatchNorm2d-29           [-1, 24, 28, 28]              48\n",
      " InvertedResidual-30           [-1, 24, 28, 28]               0\n",
      "           Conv2d-31           [-1, 72, 28, 28]           1,728\n",
      "      BatchNorm2d-32           [-1, 72, 28, 28]             144\n",
      "             ReLU-33           [-1, 72, 28, 28]               0\n",
      "           Conv2d-34           [-1, 72, 14, 14]           1,800\n",
      "      BatchNorm2d-35           [-1, 72, 14, 14]             144\n",
      "             ReLU-36           [-1, 72, 14, 14]               0\n",
      "AdaptiveAvgPool2d-37             [-1, 72, 1, 1]               0\n",
      "           Conv2d-38             [-1, 24, 1, 1]           1,752\n",
      "             ReLU-39             [-1, 24, 1, 1]               0\n",
      "           Conv2d-40             [-1, 72, 1, 1]           1,800\n",
      "      Hardsigmoid-41             [-1, 72, 1, 1]               0\n",
      "SqueezeExcitation-42           [-1, 72, 14, 14]               0\n",
      "           Conv2d-43           [-1, 40, 14, 14]           2,880\n",
      "      BatchNorm2d-44           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-45           [-1, 40, 14, 14]               0\n",
      "           Conv2d-46          [-1, 120, 14, 14]           4,800\n",
      "      BatchNorm2d-47          [-1, 120, 14, 14]             240\n",
      "             ReLU-48          [-1, 120, 14, 14]               0\n",
      "           Conv2d-49          [-1, 120, 14, 14]           3,000\n",
      "      BatchNorm2d-50          [-1, 120, 14, 14]             240\n",
      "             ReLU-51          [-1, 120, 14, 14]               0\n",
      "AdaptiveAvgPool2d-52            [-1, 120, 1, 1]               0\n",
      "           Conv2d-53             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-54             [-1, 32, 1, 1]               0\n",
      "           Conv2d-55            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-56            [-1, 120, 1, 1]               0\n",
      "SqueezeExcitation-57          [-1, 120, 14, 14]               0\n",
      "           Conv2d-58           [-1, 40, 14, 14]           4,800\n",
      "      BatchNorm2d-59           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-60           [-1, 40, 14, 14]               0\n",
      "           Conv2d-61          [-1, 120, 14, 14]           4,800\n",
      "      BatchNorm2d-62          [-1, 120, 14, 14]             240\n",
      "             ReLU-63          [-1, 120, 14, 14]               0\n",
      "           Conv2d-64          [-1, 120, 14, 14]           3,000\n",
      "      BatchNorm2d-65          [-1, 120, 14, 14]             240\n",
      "             ReLU-66          [-1, 120, 14, 14]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 120, 1, 1]               0\n",
      "           Conv2d-68             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-69             [-1, 32, 1, 1]               0\n",
      "           Conv2d-70            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-71            [-1, 120, 1, 1]               0\n",
      "SqueezeExcitation-72          [-1, 120, 14, 14]               0\n",
      "           Conv2d-73           [-1, 40, 14, 14]           4,800\n",
      "      BatchNorm2d-74           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-75           [-1, 40, 14, 14]               0\n",
      "           Conv2d-76          [-1, 240, 14, 14]           9,600\n",
      "      BatchNorm2d-77          [-1, 240, 14, 14]             480\n",
      "        Hardswish-78          [-1, 240, 14, 14]               0\n",
      "           Conv2d-79            [-1, 240, 7, 7]           2,160\n",
      "      BatchNorm2d-80            [-1, 240, 7, 7]             480\n",
      "        Hardswish-81            [-1, 240, 7, 7]               0\n",
      "           Conv2d-82             [-1, 80, 7, 7]          19,200\n",
      "      BatchNorm2d-83             [-1, 80, 7, 7]             160\n",
      " InvertedResidual-84             [-1, 80, 7, 7]               0\n",
      "           Conv2d-85            [-1, 200, 7, 7]          16,000\n",
      "      BatchNorm2d-86            [-1, 200, 7, 7]             400\n",
      "        Hardswish-87            [-1, 200, 7, 7]               0\n",
      "           Conv2d-88            [-1, 200, 7, 7]           1,800\n",
      "      BatchNorm2d-89            [-1, 200, 7, 7]             400\n",
      "        Hardswish-90            [-1, 200, 7, 7]               0\n",
      "           Conv2d-91             [-1, 80, 7, 7]          16,000\n",
      "      BatchNorm2d-92             [-1, 80, 7, 7]             160\n",
      " InvertedResidual-93             [-1, 80, 7, 7]               0\n",
      "           Conv2d-94            [-1, 184, 7, 7]          14,720\n",
      "      BatchNorm2d-95            [-1, 184, 7, 7]             368\n",
      "        Hardswish-96            [-1, 184, 7, 7]               0\n",
      "           Conv2d-97            [-1, 184, 7, 7]           1,656\n",
      "      BatchNorm2d-98            [-1, 184, 7, 7]             368\n",
      "        Hardswish-99            [-1, 184, 7, 7]               0\n",
      "          Conv2d-100             [-1, 80, 7, 7]          14,720\n",
      "     BatchNorm2d-101             [-1, 80, 7, 7]             160\n",
      "InvertedResidual-102             [-1, 80, 7, 7]               0\n",
      "          Conv2d-103            [-1, 184, 7, 7]          14,720\n",
      "     BatchNorm2d-104            [-1, 184, 7, 7]             368\n",
      "       Hardswish-105            [-1, 184, 7, 7]               0\n",
      "          Conv2d-106            [-1, 184, 7, 7]           1,656\n",
      "     BatchNorm2d-107            [-1, 184, 7, 7]             368\n",
      "       Hardswish-108            [-1, 184, 7, 7]               0\n",
      "          Conv2d-109             [-1, 80, 7, 7]          14,720\n",
      "     BatchNorm2d-110             [-1, 80, 7, 7]             160\n",
      "InvertedResidual-111             [-1, 80, 7, 7]               0\n",
      "          Conv2d-112            [-1, 480, 7, 7]          38,400\n",
      "     BatchNorm2d-113            [-1, 480, 7, 7]             960\n",
      "       Hardswish-114            [-1, 480, 7, 7]               0\n",
      "          Conv2d-115            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-116            [-1, 480, 7, 7]             960\n",
      "       Hardswish-117            [-1, 480, 7, 7]               0\n",
      "AdaptiveAvgPool2d-118            [-1, 480, 1, 1]               0\n",
      "          Conv2d-119            [-1, 120, 1, 1]          57,720\n",
      "            ReLU-120            [-1, 120, 1, 1]               0\n",
      "          Conv2d-121            [-1, 480, 1, 1]          58,080\n",
      "     Hardsigmoid-122            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-123            [-1, 480, 7, 7]               0\n",
      "          Conv2d-124            [-1, 112, 7, 7]          53,760\n",
      "     BatchNorm2d-125            [-1, 112, 7, 7]             224\n",
      "InvertedResidual-126            [-1, 112, 7, 7]               0\n",
      "          Conv2d-127            [-1, 672, 7, 7]          75,264\n",
      "     BatchNorm2d-128            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-129            [-1, 672, 7, 7]               0\n",
      "          Conv2d-130            [-1, 672, 7, 7]           6,048\n",
      "     BatchNorm2d-131            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-132            [-1, 672, 7, 7]               0\n",
      "AdaptiveAvgPool2d-133            [-1, 672, 1, 1]               0\n",
      "          Conv2d-134            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-135            [-1, 168, 1, 1]               0\n",
      "          Conv2d-136            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-137            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-138            [-1, 672, 7, 7]               0\n",
      "          Conv2d-139            [-1, 112, 7, 7]          75,264\n",
      "     BatchNorm2d-140            [-1, 112, 7, 7]             224\n",
      "InvertedResidual-141            [-1, 112, 7, 7]               0\n",
      "          Conv2d-142            [-1, 672, 7, 7]          75,264\n",
      "     BatchNorm2d-143            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-144            [-1, 672, 7, 7]               0\n",
      "          Conv2d-145            [-1, 672, 4, 4]          16,800\n",
      "     BatchNorm2d-146            [-1, 672, 4, 4]           1,344\n",
      "       Hardswish-147            [-1, 672, 4, 4]               0\n",
      "AdaptiveAvgPool2d-148            [-1, 672, 1, 1]               0\n",
      "          Conv2d-149            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-150            [-1, 168, 1, 1]               0\n",
      "          Conv2d-151            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-152            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-153            [-1, 672, 4, 4]               0\n",
      "          Conv2d-154            [-1, 160, 4, 4]         107,520\n",
      "     BatchNorm2d-155            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-156            [-1, 160, 4, 4]               0\n",
      "          Conv2d-157            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-158            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-159            [-1, 960, 4, 4]               0\n",
      "          Conv2d-160            [-1, 960, 4, 4]          24,000\n",
      "     BatchNorm2d-161            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-162            [-1, 960, 4, 4]               0\n",
      "AdaptiveAvgPool2d-163            [-1, 960, 1, 1]               0\n",
      "          Conv2d-164            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-165            [-1, 240, 1, 1]               0\n",
      "          Conv2d-166            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-167            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-168            [-1, 960, 4, 4]               0\n",
      "          Conv2d-169            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-170            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-171            [-1, 160, 4, 4]               0\n",
      "          Conv2d-172            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-173            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-174            [-1, 960, 4, 4]               0\n",
      "          Conv2d-175            [-1, 960, 4, 4]          24,000\n",
      "     BatchNorm2d-176            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-177            [-1, 960, 4, 4]               0\n",
      "AdaptiveAvgPool2d-178            [-1, 960, 1, 1]               0\n",
      "          Conv2d-179            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-180            [-1, 240, 1, 1]               0\n",
      "          Conv2d-181            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-182            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-183            [-1, 960, 4, 4]               0\n",
      "          Conv2d-184            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-185            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-186            [-1, 160, 4, 4]               0\n",
      "          Conv2d-187            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-188            [-1, 960, 4, 4]           1,920\n",
      "       Hardswish-189            [-1, 960, 4, 4]               0\n",
      "          Conv2d-190           [-1, 20, 14, 14]         180,020\n",
      "     BatchNorm2d-191           [-1, 20, 14, 14]              40\n",
      "          Conv2d-192           [-1, 20, 14, 14]           3,620\n",
      "     BatchNorm2d-193           [-1, 20, 14, 14]              40\n",
      "   UpsampleBlock-194           [-1, 20, 14, 14]               0\n",
      "          Conv2d-195           [-1, 16, 28, 28]           6,352\n",
      "     BatchNorm2d-196           [-1, 16, 28, 28]              32\n",
      "          Conv2d-197           [-1, 16, 28, 28]           2,320\n",
      "     BatchNorm2d-198           [-1, 16, 28, 28]              32\n",
      "   UpsampleBlock-199           [-1, 16, 28, 28]               0\n",
      "          Conv2d-200           [-1, 16, 28, 28]           5,776\n",
      "     BatchNorm2d-201           [-1, 16, 28, 28]              32\n",
      "          Conv2d-202           [-1, 16, 28, 28]           2,320\n",
      "     BatchNorm2d-203           [-1, 16, 28, 28]              32\n",
      "   UpsampleBlock-204           [-1, 16, 28, 28]               0\n",
      "          Conv2d-205           [-1, 16, 56, 56]           4,624\n",
      "     BatchNorm2d-206           [-1, 16, 56, 56]              32\n",
      "          Conv2d-207           [-1, 16, 56, 56]           2,320\n",
      "     BatchNorm2d-208           [-1, 16, 56, 56]              32\n",
      "   UpsampleBlock-209           [-1, 16, 56, 56]               0\n",
      "        Upsample-210         [-1, 16, 112, 112]               0\n",
      "          Conv2d-211          [-1, 1, 112, 112]              17\n",
      "================================================================\n",
      "Total params: 3,179,769\n",
      "Trainable params: 3,179,769\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 32.80\n",
      "Params size (MB): 12.13\n",
      "Estimated Total Size (MB): 45.13\n",
      "----------------------------------------------------------------\n",
      "Output shape: torch.Size([1, 1, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MobileNetV3UNetv7(in_channels=4, out_channels=1, config_name=\"large\", backbone=True).to(device)\n",
    "\n",
    "dummy_input = torch.randn(1, 4, 112, 112).to(device)\n",
    "output = model(dummy_input)\n",
    "print(model)\n",
    "summary(model, input_size=(4,112,112), device=str(device))\n",
    "print(\"Output shape:\", output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
