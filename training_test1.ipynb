{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import os\n",
    "\n",
    "def dice_coefficient(pred, target, smooth=1e-6):\n",
    "    pred_sig = torch.sigmoid(pred)\n",
    "    intersection = (pred_sig * target).sum(dim=(2,3))\n",
    "    union = pred_sig.sum(dim=(2,3)) + target.sum(dim=(2,3))\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice.mean()\n",
    "\n",
    "def combined_loss(pred, target, smooth=1e-6, alpha=0.5):\n",
    "    # Dice loss part\n",
    "    pred_sig = torch.sigmoid(pred)\n",
    "    intersection = (pred_sig * target).sum(dim=(2,3))\n",
    "    union = pred_sig.sum(dim=(2,3)) + target.sum(dim=(2,3))\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss = 1 - dice.mean()\n",
    "\n",
    "    # BCE loss part\n",
    "    bce_loss = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    return alpha * dice_loss + (1 - alpha) * bce_loss\n",
    "\n",
    "def validate_model(model, val_loader, device, criterion):\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    dice_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch_inp, batch_mask in val_loader:\n",
    "            # batch_inp: (1, num_frames, 4, H, W)\n",
    "            # batch_mask: (1, num_frames, 1, H, W)\n",
    "            batch_inp = batch_inp.squeeze(0).to(device)   # (num_frames,4,H,W)\n",
    "            batch_mask = batch_mask.squeeze(0).to(device) # (num_frames,1,H,W)\n",
    "\n",
    "            pred_mask = model(batch_inp)\n",
    "            loss = criterion(pred_mask, batch_mask)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            # Compute Dice coefficient for logging\n",
    "            dice_val = dice_coefficient(pred_mask, batch_mask)\n",
    "            dice_scores.append(dice_val.item())\n",
    "\n",
    "    return np.mean(val_losses), np.mean(dice_scores)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, num_epochs=10, lr=1e-4, log_dir=None, save_path='best_model.pth'):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = combined_loss\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Optional TensorBoard logging\n",
    "    writer = None\n",
    "    if log_dir is not None:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_dice_scores = []\n",
    "\n",
    "        for batch_inp, batch_mask in train_loader:\n",
    "            batch_inp = batch_inp.squeeze(0).to(device)   # (num_frames,4,H,W)\n",
    "            batch_mask = batch_mask.squeeze(0).to(device) # (num_frames,1,H,W)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                pred_mask = model(batch_inp)\n",
    "                loss = criterion(pred_mask, batch_mask)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            # Dice score for train batch\n",
    "            dice_train = dice_coefficient(pred_mask, batch_mask)\n",
    "            train_dice_scores.append(dice_train.item())\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_dice = validate_model(model, val_loader, device, criterion)\n",
    "        train_loss_mean = np.mean(train_losses)\n",
    "        train_dice_mean = np.mean(train_dice_scores)\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('Loss/train', train_loss_mean, epoch)\n",
    "            writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "            writer.add_scalar('Dice/train', train_dice_mean, epoch)\n",
    "            writer.add_scalar('Dice/val', val_dice, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {train_loss_mean:.4f}, Train Dice: {train_dice_mean:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}\")\n",
    "\n",
    "        # LR scheduler step\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Model checkpointing\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_val_loss,\n",
    "            }, save_path)\n",
    "            print(f\"Best model updated at epoch {epoch+1} with Val Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hc4293/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hc4293/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hc4293/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2947182/2713163688.py:55: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/home/hc4293/echoframe/dataloaderv2.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  m = torch.load(mask_path)\n",
      "/tmp/ipykernel_2947182/2713163688.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m MobileNetV3UNet(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, backbone_pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Train the model with improved training loop\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m     26\u001b[0m     model,\n\u001b[1;32m     27\u001b[0m     train_loader,\n\u001b[1;32m     28\u001b[0m     val_loader,\n\u001b[1;32m     29\u001b[0m     device,\n\u001b[1;32m     30\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     31\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m     32\u001b[0m     log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# optional: provide a directory for TensorBoard logs\u001b[39;00m\n\u001b[1;32m     33\u001b[0m )\n",
      "Cell \u001b[0;32mIn[1], line 80\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, device, num_epochs, lr, log_dir, save_path)\u001b[0m\n\u001b[1;32m     77\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred_mask, batch_mask)\n\u001b[1;32m     79\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 80\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     81\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     83\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/miniconda3/envs/imgsenv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloaderv2 import EchoVideoDataset\n",
    "from modelv6 import MobileNetV3UNet\n",
    "# from utils import train_model\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize datasets\n",
    "train_dataset = EchoVideoDataset(root=\"./data/echodynamic\", split='train')\n",
    "val_dataset = EchoVideoDataset(root=\"./data/echodynamic\", split='val')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Initialize the model with 4 channels and a pretrained backbone\n",
    "# The updated model architecture handles the extra mask channel internally,\n",
    "# so no manual weight adaptation is needed now.\n",
    "model = MobileNetV3UNet(in_channels=4, out_channels=1, backbone_pretrained=True).to(device)\n",
    "\n",
    "# Train the model with improved training loop\n",
    "model = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    log_dir=\"./logs\"  # optional: provide a directory for TensorBoard logs\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
