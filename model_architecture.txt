digraph {
	graph [size="193.35,193.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139934129711904 [label="
 (1, 1, 112, 112)" fillcolor=darkolivegreen1]
	139934152260816 [label=ConvolutionBackward0]
	139934152251408 -> 139934152260816
	139934152251408 [label=UpsampleBilinear2DBackward0]
	139934152261104 -> 139934152251408
	139934152261104 [label=ReluBackward0]
	139934152258848 -> 139934152261104
	139934152258848 [label=CudnnBatchNormBackward0]
	139934152261344 -> 139934152258848
	139934152261344 [label=ConvolutionBackward0]
	139934152260912 -> 139934152261344
	139934152260912 [label=ReluBackward0]
	139934152247088 -> 139934152260912
	139934152247088 [label=CudnnBatchNormBackward0]
	139934152246704 -> 139934152247088
	139934152246704 [label=ConvolutionBackward0]
	139934152245696 -> 139934152246704
	139934152245696 [label=CatBackward0]
	139934152246176 -> 139934152245696
	139934152246176 [label=UpsampleBilinear2DBackward0]
	139934152245936 -> 139934152246176
	139934152245936 [label=ReluBackward0]
	139934152245984 -> 139934152245936
	139934152245984 [label=CudnnBatchNormBackward0]
	139934152247136 -> 139934152245984
	139934152247136 [label=ConvolutionBackward0]
	139934152246560 -> 139934152247136
	139934152246560 [label=ReluBackward0]
	139934152249584 -> 139934152246560
	139934152249584 [label=CudnnBatchNormBackward0]
	139934152246848 -> 139934152249584
	139934152246848 [label=ConvolutionBackward0]
	139934152249056 -> 139934152246848
	139934152249056 [label=CatBackward0]
	139934152248288 -> 139934152249056
	139934152248288 [label=UpsampleBilinear2DBackward0]
	139934152249344 -> 139934152248288
	139934152249344 [label=ReluBackward0]
	139934152248000 -> 139934152249344
	139934152248000 [label=CudnnBatchNormBackward0]
	139934152247424 -> 139934152248000
	139934152247424 [label=ConvolutionBackward0]
	139934152248864 -> 139934152247424
	139934152248864 [label=ReluBackward0]
	139934152250160 -> 139934152248864
	139934152250160 [label=CudnnBatchNormBackward0]
	139934152249152 -> 139934152250160
	139934152249152 [label=ConvolutionBackward0]
	139934152250880 -> 139934152249152
	139934152250880 [label=CatBackward0]
	139934152250352 -> 139934152250880
	139934152250352 [label=UpsampleBilinear2DBackward0]
	139934152250592 -> 139934152250352
	139934152250592 [label=ReluBackward0]
	139934152250832 -> 139934152250592
	139934152250832 [label=CudnnBatchNormBackward0]
	139934152253760 -> 139934152250832
	139934152253760 [label=ConvolutionBackward0]
	139934152251360 -> 139934152253760
	139934152251360 [label=ReluBackward0]
	139934152251840 -> 139934152251360
	139934152251840 [label=CudnnBatchNormBackward0]
	139934152251648 -> 139934152251840
	139934152251648 [label=ConvolutionBackward0]
	139934152252272 -> 139934152251648
	139934152252272 [label=CatBackward0]
	139934152252080 -> 139934152252272
	139934152252080 [label=UpsampleBilinear2DBackward0]
	139934152255152 -> 139934152252080
	139934152255152 [label=HardswishBackward0]
	139934152253472 -> 139934152255152
	139934152253472 [label=CudnnBatchNormBackward0]
	139934152252848 -> 139934152253472
	139934152252848 [label=ConvolutionBackward0]
	139934152253088 -> 139934152252848
	139934152253088 [label=AddBackward0]
	139934152253184 -> 139934152253088
	139934152253184 [label=CudnnBatchNormBackward0]
	139934152253520 -> 139934152253184
	139934152253520 [label=ConvolutionBackward0]
	139934152253280 -> 139934152253520
	139934152253280 [label=MulBackward0]
	139934152254864 -> 139934152253280
	139934152254864 [label=HardsigmoidBackward0]
	139934152254288 -> 139934152254864
	139934152254288 [label=ConvolutionBackward0]
	139934152252704 -> 139934152254288
	139934152252704 [label=ReluBackward0]
	139934152254816 -> 139934152252704
	139934152254816 [label=ConvolutionBackward0]
	139934152254672 -> 139934152254816
	139934152254672 [label=MeanBackward1]
	139934152254576 -> 139934152254672
	139934152254576 [label=HardswishBackward0]
	139934152254960 -> 139934152254576
	139934152254960 [label=CudnnBatchNormBackward0]
	139934152254720 -> 139934152254960
	139934152254720 [label=ConvolutionBackward0]
	139934152258224 -> 139934152254720
	139934152258224 [label=HardswishBackward0]
	139934152255728 -> 139934152258224
	139934152255728 [label=CudnnBatchNormBackward0]
	139934152256832 -> 139934152255728
	139934152256832 [label=ConvolutionBackward0]
	139934152252896 -> 139934152256832
	139934152252896 [label=AddBackward0]
	139934152255104 -> 139934152252896
	139934152255104 [label=CudnnBatchNormBackward0]
	139934152255632 -> 139934152255104
	139934152255632 [label=ConvolutionBackward0]
	139934152256352 -> 139934152255632
	139934152256352 [label=MulBackward0]
	139934152256688 -> 139934152256352
	139934152256688 [label=HardsigmoidBackward0]
	139934152256784 -> 139934152256688
	139934152256784 [label=ConvolutionBackward0]
	139934152255680 -> 139934152256784
	139934152255680 [label=ReluBackward0]
	139934152257024 -> 139934152255680
	139934152257024 [label=ConvolutionBackward0]
	139934152257504 -> 139934152257024
	139934152257504 [label=MeanBackward1]
	139934152257168 -> 139934152257504
	139934152257168 [label=HardswishBackward0]
	139934152257984 -> 139934152257168
	139934152257984 [label=CudnnBatchNormBackward0]
	139934152258080 -> 139934152257984
	139934152258080 [label=ConvolutionBackward0]
	139934152258128 -> 139934152258080
	139934152258128 [label=HardswishBackward0]
	139934152258560 -> 139934152258128
	139934152258560 [label=CudnnBatchNormBackward0]
	139934152257264 -> 139934152258560
	139934152257264 [label=ConvolutionBackward0]
	139934152256400 -> 139934152257264
	139934152256400 [label=CudnnBatchNormBackward0]
	139934152259712 -> 139934152256400
	139934152259712 [label=ConvolutionBackward0]
	139934152260528 -> 139934152259712
	139934152260528 [label=MulBackward0]
	139934151754992 -> 139934152260528
	139934151754992 [label=HardsigmoidBackward0]
	139938491341344 -> 139934151754992
	139938491341344 [label=ConvolutionBackward0]
	139938491334960 -> 139938491341344
	139938491334960 [label=ReluBackward0]
	139934339028912 -> 139938491334960
	139934339028912 [label=ConvolutionBackward0]
	139934151917184 -> 139934339028912
	139934151917184 [label=MeanBackward1]
	139934151759264 -> 139934151917184
	139934151759264 [label=HardswishBackward0]
	139934151915360 -> 139934151759264
	139934151915360 [label=CudnnBatchNormBackward0]
	139934151916128 -> 139934151915360
	139934151916128 [label=ConvolutionBackward0]
	139934151916896 -> 139934151916128
	139934151916896 [label=HardswishBackward0]
	139934151911184 -> 139934151916896
	139934151911184 [label=CudnnBatchNormBackward0]
	139934151917424 -> 139934151911184
	139934151917424 [label=ConvolutionBackward0]
	139934151916464 -> 139934151917424
	139934151916464 [label=AddBackward0]
	139934151911088 -> 139934151916464
	139934151911088 [label=CudnnBatchNormBackward0]
	139934151911328 -> 139934151911088
	139934151911328 [label=ConvolutionBackward0]
	139934151910800 -> 139934151911328
	139934151910800 [label=MulBackward0]
	139934151910560 -> 139934151910800
	139934151910560 [label=HardsigmoidBackward0]
	139934151910656 -> 139934151910560
	139934151910656 [label=ConvolutionBackward0]
	139934151911856 -> 139934151910656
	139934151911856 [label=ReluBackward0]
	139934151908880 -> 139934151911856
	139934151908880 [label=ConvolutionBackward0]
	139934151912672 -> 139934151908880
	139934151912672 [label=MeanBackward1]
	139934151911712 -> 139934151912672
	139934151911712 [label=HardswishBackward0]
	139934151912288 -> 139934151911712
	139934151912288 [label=CudnnBatchNormBackward0]
	139934151912240 -> 139934151912288
	139934151912240 [label=ConvolutionBackward0]
	139934151913104 -> 139934151912240
	139934151913104 [label=HardswishBackward0]
	139934151913248 -> 139934151913104
	139934151913248 [label=CudnnBatchNormBackward0]
	139934151912960 -> 139934151913248
	139934151912960 [label=ConvolutionBackward0]
	139934151913488 -> 139934151912960
	139934151913488 [label=CudnnBatchNormBackward0]
	139934151916032 -> 139934151913488
	139934151916032 [label=ConvolutionBackward0]
	139934151913728 -> 139934151916032
	139934151913728 [label=MulBackward0]
	139934151914304 -> 139934151913728
	139934151914304 [label=HardsigmoidBackward0]
	139934151913344 -> 139934151914304
	139934151913344 [label=ConvolutionBackward0]
	139934151914064 -> 139934151913344
	139934151914064 [label=ReluBackward0]
	139934151915024 -> 139934151914064
	139934151915024 [label=ConvolutionBackward0]
	139934151914592 -> 139934151915024
	139934151914592 [label=MeanBackward1]
	139934151913968 -> 139934151914592
	139934151913968 [label=HardswishBackward0]
	139934151913776 -> 139934151913968
	139934151913776 [label=CudnnBatchNormBackward0]
	139934151916272 -> 139934151913776
	139934151916272 [label=ConvolutionBackward0]
	139934151915216 -> 139934151916272
	139934151915216 [label=HardswishBackward0]
	139934151915504 -> 139934151915216
	139934151915504 [label=CudnnBatchNormBackward0]
	139934151915984 -> 139934151915504
	139934151915984 [label=ConvolutionBackward0]
	139934151916416 -> 139934151915984
	139934151916416 [label=AddBackward0]
	139934151910032 -> 139934151916416
	139934151910032 [label=CudnnBatchNormBackward0]
	139934151911424 -> 139934151910032
	139934151911424 [label=ConvolutionBackward0]
	139934151910320 -> 139934151911424
	139934151910320 [label=HardswishBackward0]
	139938493169136 -> 139934151910320
	139938493169136 [label=CudnnBatchNormBackward0]
	139934129741952 -> 139938493169136
	139934129741952 [label=ConvolutionBackward0]
	139934129741760 -> 139934129741952
	139934129741760 [label=HardswishBackward0]
	139934129747040 -> 139934129741760
	139934129747040 [label=CudnnBatchNormBackward0]
	139934129742336 -> 139934129747040
	139934129742336 [label=ConvolutionBackward0]
	139934151911520 -> 139934129742336
	139934151911520 [label=AddBackward0]
	139934129743680 -> 139934151911520
	139934129743680 [label=CudnnBatchNormBackward0]
	139934129744592 -> 139934129743680
	139934129744592 [label=ConvolutionBackward0]
	139934129744208 -> 139934129744592
	139934129744208 [label=HardswishBackward0]
	139934129744352 -> 139934129744208
	139934129744352 [label=CudnnBatchNormBackward0]
	139934129748624 -> 139934129744352
	139934129748624 [label=ConvolutionBackward0]
	139934129745600 -> 139934129748624
	139934129745600 [label=HardswishBackward0]
	139934129740608 -> 139934129745600
	139934129740608 [label=CudnnBatchNormBackward0]
	139934129748576 -> 139934129740608
	139934129748576 [label=ConvolutionBackward0]
	139934129743488 -> 139934129748576
	139934129743488 [label=AddBackward0]
	139934129746176 -> 139934129743488
	139934129746176 [label=CudnnBatchNormBackward0]
	139934129748864 -> 139934129746176
	139934129748864 [label=ConvolutionBackward0]
	139934129749824 -> 139934129748864
	139934129749824 [label=HardswishBackward0]
	139934129745024 -> 139934129749824
	139934129745024 [label=CudnnBatchNormBackward0]
	139934129743440 -> 139934129745024
	139934129743440 [label=ConvolutionBackward0]
	139934129747712 -> 139934129743440
	139934129747712 [label=HardswishBackward0]
	139934129738064 -> 139934129747712
	139934129738064 [label=CudnnBatchNormBackward0]
	139934129747184 -> 139934129738064
	139934129747184 [label=ConvolutionBackward0]
	139934129747280 -> 139934129747184
	139934129747280 [label=CudnnBatchNormBackward0]
	139934129748000 -> 139934129747280
	139934129748000 [label=ConvolutionBackward0]
	139934129744688 -> 139934129748000
	139934129744688 [label=HardswishBackward0]
	139934129747760 -> 139934129744688
	139934129747760 [label=CudnnBatchNormBackward0]
	139934129738304 -> 139934129747760
	139934129738304 [label=ConvolutionBackward0]
	139934129739216 -> 139934129738304
	139934129739216 [label=HardswishBackward0]
	139934129740080 -> 139934129739216
	139934129740080 [label=CudnnBatchNormBackward0]
	139934129740464 -> 139934129740080
	139934129740464 [label=ConvolutionBackward0]
	139934129734656 -> 139934129740464
	139934129734656 [label=AddBackward0]
	139934130140784 -> 139934129734656
	139934130140784 [label=CudnnBatchNormBackward0]
	139934130138768 -> 139934130140784
	139934130138768 [label=ConvolutionBackward0]
	139934129873936 -> 139934130138768
	139934129873936 [label=MulBackward0]
	139934129865296 -> 139934129873936
	139934129865296 [label=HardsigmoidBackward0]
	139934129865536 -> 139934129865296
	139934129865536 [label=ConvolutionBackward0]
	139934129874080 -> 139934129865536
	139934129874080 [label=ReluBackward0]
	139934130646624 -> 139934129874080
	139934130646624 [label=ConvolutionBackward0]
	139934130634864 -> 139934130646624
	139934130634864 [label=MeanBackward1]
	139934129865344 -> 139934130634864
	139934129865344 [label=ReluBackward0]
	139934130639520 -> 139934129865344
	139934130639520 [label=CudnnBatchNormBackward0]
	139934130640384 -> 139934130639520
	139934130640384 [label=ConvolutionBackward0]
	139934130647776 -> 139934130640384
	139934130647776 [label=ReluBackward0]
	139934130647872 -> 139934130647776
	139934130647872 [label=CudnnBatchNormBackward0]
	139934130648064 -> 139934130647872
	139934130648064 [label=ConvolutionBackward0]
	139934152252032 -> 139934130648064
	139934152252032 [label=AddBackward0]
	139934130648928 -> 139934152252032
	139934130648928 [label=CudnnBatchNormBackward0]
	139934130649360 -> 139934130648928
	139934130649360 [label=ConvolutionBackward0]
	139934130649552 -> 139934130649360
	139934130649552 [label=MulBackward0]
	139934130649648 -> 139934130649552
	139934130649648 [label=HardsigmoidBackward0]
	139934130649792 -> 139934130649648
	139934130649792 [label=ConvolutionBackward0]
	139934130649888 -> 139934130649792
	139934130649888 [label=ReluBackward0]
	139934130650080 -> 139934130649888
	139934130650080 [label=ConvolutionBackward0]
	139934130650176 -> 139934130650080
	139934130650176 [label=MeanBackward1]
	139934130647728 -> 139934130650176
	139934130647728 [label=ReluBackward0]
	139934130650416 -> 139934130647728
	139934130650416 [label=CudnnBatchNormBackward0]
	139934130650512 -> 139934130650416
	139934130650512 [label=ConvolutionBackward0]
	139934130650704 -> 139934130650512
	139934130650704 [label=ReluBackward0]
	139934130650848 -> 139934130650704
	139934130650848 [label=CudnnBatchNormBackward0]
	139934130650944 -> 139934130650848
	139934130650944 [label=ConvolutionBackward0]
	139934130648784 -> 139934130650944
	139934130648784 [label=CudnnBatchNormBackward0]
	139934130646960 -> 139934130648784
	139934130646960 [label=ConvolutionBackward0]
	139934130646288 -> 139934130646960
	139934130646288 [label=MulBackward0]
	139934130634960 -> 139934130646288
	139934130634960 [label=HardsigmoidBackward0]
	139934130635200 -> 139934130634960
	139934130635200 [label=ConvolutionBackward0]
	139934130635008 -> 139934130635200
	139934130635008 [label=ReluBackward0]
	139934130635584 -> 139934130635008
	139934130635584 [label=ConvolutionBackward0]
	139934130636112 -> 139934130635584
	139934130636112 [label=MeanBackward1]
	139934130634912 -> 139934130636112
	139934130634912 [label=ReluBackward0]
	139934130637072 -> 139934130634912
	139934130637072 [label=CudnnBatchNormBackward0]
	139934130636544 -> 139934130637072
	139934130636544 [label=ConvolutionBackward0]
	139934130637216 -> 139934130636544
	139934130637216 [label=ReluBackward0]
	139934130636736 -> 139934130637216
	139934130636736 [label=CudnnBatchNormBackward0]
	139934130636976 -> 139934130636736
	139934130636976 [label=ConvolutionBackward0]
	139934152250016 -> 139934130636976
	139934152250016 [label=AddBackward0]
	139934130646480 -> 139934152250016
	139934130646480 [label=CudnnBatchNormBackward0]
	139934130637456 -> 139934130646480
	139934130637456 [label=ConvolutionBackward0]
	139934130637312 -> 139934130637456
	139934130637312 [label=ReluBackward0]
	139934130637840 -> 139934130637312
	139934130637840 [label=CudnnBatchNormBackward0]
	139934130637408 -> 139934130637840
	139934130637408 [label=ConvolutionBackward0]
	139934130637936 -> 139934130637408
	139934130637936 [label=ReluBackward0]
	139934130639760 -> 139934130637936
	139934130639760 [label=CudnnBatchNormBackward0]
	139934130638896 -> 139934130639760
	139934130638896 [label=ConvolutionBackward0]
	139934152248240 -> 139934130638896
	139934152248240 [label=CudnnBatchNormBackward0]
	139934130640048 -> 139934152248240
	139934130640048 [label=ConvolutionBackward0]
	139934130639232 -> 139934130640048
	139934130639232 [label=ReluBackward0]
	139933850739632 -> 139934130639232
	139933850739632 [label=CudnnBatchNormBackward0]
	139933850733728 -> 139933850739632
	139933850733728 [label=ConvolutionBackward0]
	139933850732720 -> 139933850733728
	139933850732720 [label=ReluBackward0]
	139933850732576 -> 139933850732720
	139933850732576 [label=CudnnBatchNormBackward0]
	139933850738624 -> 139933850732576
	139933850738624 [label=ConvolutionBackward0]
	139933850734736 -> 139933850738624
	139933850734736 [label=AddBackward0]
	139933850812176 -> 139933850734736
	139933850812176 [label=CudnnBatchNormBackward0]
	139933850812080 -> 139933850812176
	139933850812080 [label=ConvolutionBackward0]
	139933850811888 -> 139933850812080
	139933850811888 [label=ReluBackward0]
	139933850811744 -> 139933850811888
	139933850811744 [label=CudnnBatchNormBackward0]
	139933850811648 -> 139933850811744
	139933850811648 [label=ConvolutionBackward0]
	139934152247040 -> 139933850811648
	139934152247040 [label=AddBackward0]
	139933850811360 -> 139934152247040
	139933850811360 [label=HardswishBackward0]
	139933850811216 -> 139933850811360
	139933850811216 [label=CudnnBatchNormBackward0]
	139933850811120 -> 139933850811216
	139933850811120 [label=ConvolutionBackward0]
	139933850810928 -> 139933850811120
	139934129707264 [label="initial_image_conv.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	139934129707264 -> 139933850810928
	139933850810928 [label=AccumulateGrad]
	139933850811168 -> 139933850811216
	139934129707424 [label="initial_image_conv.1.weight
 (16)" fillcolor=lightblue]
	139934129707424 -> 139933850811168
	139933850811168 [label=AccumulateGrad]
	139933850811312 -> 139933850811216
	139934129707744 [label="initial_image_conv.1.bias
 (16)" fillcolor=lightblue]
	139934129707744 -> 139933850811312
	139933850811312 [label=AccumulateGrad]
	139933850811408 -> 139934152247040
	139933850811408 [label=ReluBackward0]
	139934130638464 -> 139933850811408
	139934130638464 [label=CudnnBatchNormBackward0]
	139933850810832 -> 139934130638464
	139933850810832 [label=ConvolutionBackward0]
	139933850810736 -> 139933850810832
	139934129788544 [label="mask_adapter.0.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	139934129788544 -> 139933850810736
	139933850810736 [label=AccumulateGrad]
	139933850810976 -> 139934130638464
	139934129788784 [label="mask_adapter.1.weight
 (16)" fillcolor=lightblue]
	139934129788784 -> 139933850810976
	139933850810976 [label=AccumulateGrad]
	139933850811264 -> 139934130638464
	139934129788464 [label="mask_adapter.1.bias
 (16)" fillcolor=lightblue]
	139934129788464 -> 139933850811264
	139933850811264 [label=AccumulateGrad]
	139933850811456 -> 139933850811648
	139933850827296 [label="encoder.backbone_model.features.1.block.0.0.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	139933850827296 -> 139933850811456
	139933850811456 [label=AccumulateGrad]
	139933850811696 -> 139933850811744
	139933850827216 [label="encoder.backbone_model.features.1.block.0.1.weight
 (16)" fillcolor=lightblue]
	139933850827216 -> 139933850811696
	139933850811696 [label=AccumulateGrad]
	139933850811840 -> 139933850811744
	139933850827136 [label="encoder.backbone_model.features.1.block.0.1.bias
 (16)" fillcolor=lightblue]
	139933850827136 -> 139933850811840
	139933850811840 [label=AccumulateGrad]
	139933850811936 -> 139933850812080
	139933850826176 [label="encoder.backbone_model.features.1.block.1.0.weight
 (16, 16, 1, 1)" fillcolor=lightblue]
	139933850826176 -> 139933850811936
	139933850811936 [label=AccumulateGrad]
	139933850812128 -> 139933850812176
	139933850826416 [label="encoder.backbone_model.features.1.block.1.1.weight
 (16)" fillcolor=lightblue]
	139933850826416 -> 139933850812128
	139933850812128 [label=AccumulateGrad]
	139933850812272 -> 139933850812176
	139933850826256 [label="encoder.backbone_model.features.1.block.1.1.bias
 (16)" fillcolor=lightblue]
	139933850826256 -> 139933850812272
	139933850812272 [label=AccumulateGrad]
	139934152247040 -> 139933850734736
	139933850796432 -> 139933850738624
	139933850825536 [label="encoder.backbone_model.features.2.block.0.0.weight
 (64, 16, 1, 1)" fillcolor=lightblue]
	139933850825536 -> 139933850796432
	139933850796432 [label=AccumulateGrad]
	139933850737856 -> 139933850732576
	139933850825696 [label="encoder.backbone_model.features.2.block.0.1.weight
 (64)" fillcolor=lightblue]
	139933850825696 -> 139933850737856
	139933850737856 [label=AccumulateGrad]
	139933850739440 -> 139933850732576
	139933850825296 [label="encoder.backbone_model.features.2.block.0.1.bias
 (64)" fillcolor=lightblue]
	139933850825296 -> 139933850739440
	139933850739440 [label=AccumulateGrad]
	139933850740592 -> 139933850733728
	139933850824496 [label="encoder.backbone_model.features.2.block.1.0.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	139933850824496 -> 139933850740592
	139933850740592 [label=AccumulateGrad]
	139933850742608 -> 139933850739632
	139933850824736 [label="encoder.backbone_model.features.2.block.1.1.weight
 (64)" fillcolor=lightblue]
	139933850824736 -> 139933850742608
	139933850742608 [label=AccumulateGrad]
	139933850746400 -> 139933850739632
	139933850824336 [label="encoder.backbone_model.features.2.block.1.1.bias
 (64)" fillcolor=lightblue]
	139933850824336 -> 139933850746400
	139933850746400 [label=AccumulateGrad]
	139933850733152 -> 139934130640048
	139933850823856 [label="encoder.backbone_model.features.2.block.2.0.weight
 (24, 64, 1, 1)" fillcolor=lightblue]
	139933850823856 -> 139933850733152
	139933850733152 [label=AccumulateGrad]
	139934130641104 -> 139934152248240
	139933850823776 [label="encoder.backbone_model.features.2.block.2.1.weight
 (24)" fillcolor=lightblue]
	139933850823776 -> 139934130641104
	139934130641104 [label=AccumulateGrad]
	139934130638560 -> 139934152248240
	139933850823696 [label="encoder.backbone_model.features.2.block.2.1.bias
 (24)" fillcolor=lightblue]
	139933850823696 -> 139934130638560
	139934130638560 [label=AccumulateGrad]
	139934130637360 -> 139934130638896
	139933850822976 [label="encoder.backbone_model.features.3.block.0.0.weight
 (72, 24, 1, 1)" fillcolor=lightblue]
	139933850822976 -> 139934130637360
	139934130637360 [label=AccumulateGrad]
	139934130639088 -> 139934130639760
	139933850822896 [label="encoder.backbone_model.features.3.block.0.1.weight
 (72)" fillcolor=lightblue]
	139933850822896 -> 139934130639088
	139934130639088 [label=AccumulateGrad]
	139934130638608 -> 139934130639760
	139933850822736 [label="encoder.backbone_model.features.3.block.0.1.bias
 (72)" fillcolor=lightblue]
	139933850822736 -> 139934130638608
	139934130638608 [label=AccumulateGrad]
	139934130637600 -> 139934130637408
	139933850822016 [label="encoder.backbone_model.features.3.block.1.0.weight
 (72, 1, 3, 3)" fillcolor=lightblue]
	139933850822016 -> 139934130637600
	139934130637600 [label=AccumulateGrad]
	139934130637888 -> 139934130637840
	139933850821936 [label="encoder.backbone_model.features.3.block.1.1.weight
 (72)" fillcolor=lightblue]
	139933850821936 -> 139934130637888
	139934130637888 [label=AccumulateGrad]
	139934130637792 -> 139934130637840
	139933850821776 [label="encoder.backbone_model.features.3.block.1.1.bias
 (72)" fillcolor=lightblue]
	139933850821776 -> 139934130637792
	139934130637792 [label=AccumulateGrad]
	139934130637552 -> 139934130637456
	139933850821136 [label="encoder.backbone_model.features.3.block.2.0.weight
 (24, 72, 1, 1)" fillcolor=lightblue]
	139933850821136 -> 139934130637552
	139934130637552 [label=AccumulateGrad]
	139934130638224 -> 139934130646480
	139933850821376 [label="encoder.backbone_model.features.3.block.2.1.weight
 (24)" fillcolor=lightblue]
	139933850821376 -> 139934130638224
	139934130638224 [label=AccumulateGrad]
	139934130637024 -> 139934130646480
	139933850820976 [label="encoder.backbone_model.features.3.block.2.1.bias
 (24)" fillcolor=lightblue]
	139933850820976 -> 139934130637024
	139934130637024 [label=AccumulateGrad]
	139934152248240 -> 139934152250016
	139934130636784 -> 139934130636976
	139933850820176 [label="encoder.backbone_model.features.4.block.0.0.weight
 (72, 24, 1, 1)" fillcolor=lightblue]
	139933850820176 -> 139934130636784
	139934130636784 [label=AccumulateGrad]
	139934130636256 -> 139934130636736
	139933850820416 [label="encoder.backbone_model.features.4.block.0.1.weight
 (72)" fillcolor=lightblue]
	139933850820416 -> 139934130636256
	139934130636256 [label=AccumulateGrad]
	139934130636640 -> 139934130636736
	139933850820256 [label="encoder.backbone_model.features.4.block.0.1.bias
 (72)" fillcolor=lightblue]
	139933850820256 -> 139934130636640
	139934130636640 [label=AccumulateGrad]
	139934130636160 -> 139934130636544
	139933850819376 [label="encoder.backbone_model.features.4.block.1.0.weight
 (72, 1, 5, 5)" fillcolor=lightblue]
	139933850819376 -> 139934130636160
	139934130636160 [label=AccumulateGrad]
	139934130636304 -> 139934130637072
	139933850819616 [label="encoder.backbone_model.features.4.block.1.1.weight
 (72)" fillcolor=lightblue]
	139933850819616 -> 139934130636304
	139934130636304 [label=AccumulateGrad]
	139934130635296 -> 139934130637072
	139933850819216 [label="encoder.backbone_model.features.4.block.1.1.bias
 (72)" fillcolor=lightblue]
	139933850819216 -> 139934130635296
	139934130635296 [label=AccumulateGrad]
	139934130635104 -> 139934130635584
	139933850818656 [label="encoder.backbone_model.features.4.block.2.fc1.weight
 (24, 72, 1, 1)" fillcolor=lightblue]
	139933850818656 -> 139934130635104
	139934130635104 [label=AccumulateGrad]
	139934130635488 -> 139934130635584
	139933850818736 [label="encoder.backbone_model.features.4.block.2.fc1.bias
 (24)" fillcolor=lightblue]
	139933850818736 -> 139934130635488
	139934130635488 [label=AccumulateGrad]
	139934130635248 -> 139934130635200
	139933850818336 [label="encoder.backbone_model.features.4.block.2.fc2.weight
 (72, 24, 1, 1)" fillcolor=lightblue]
	139933850818336 -> 139934130635248
	139934130635248 [label=AccumulateGrad]
	139934130635920 -> 139934130635200
	139933850818416 [label="encoder.backbone_model.features.4.block.2.fc2.bias
 (72)" fillcolor=lightblue]
	139933850818416 -> 139934130635920
	139934130635920 [label=AccumulateGrad]
	139934130634912 -> 139934130646288
	139934130646192 -> 139934130646960
	139933850818096 [label="encoder.backbone_model.features.4.block.3.0.weight
 (40, 72, 1, 1)" fillcolor=lightblue]
	139933850818096 -> 139934130646192
	139934130646192 [label=AccumulateGrad]
	139934130647248 -> 139934130648784
	139933850818016 [label="encoder.backbone_model.features.4.block.3.1.weight
 (40)" fillcolor=lightblue]
	139933850818016 -> 139934130647248
	139934130647248 [label=AccumulateGrad]
	139934130651040 -> 139934130648784
	139933850817856 [label="encoder.backbone_model.features.4.block.3.1.bias
 (40)" fillcolor=lightblue]
	139933850817856 -> 139934130651040
	139934130651040 [label=AccumulateGrad]
	139934130647584 -> 139934130650944
	139933850817136 [label="encoder.backbone_model.features.5.block.0.0.weight
 (120, 40, 1, 1)" fillcolor=lightblue]
	139933850817136 -> 139934130647584
	139934130647584 [label=AccumulateGrad]
	139934130650896 -> 139934130650848
	139933850817216 [label="encoder.backbone_model.features.5.block.0.1.weight
 (120)" fillcolor=lightblue]
	139933850817216 -> 139934130650896
	139934130650896 [label=AccumulateGrad]
	139934130650752 -> 139934130650848
	139933850816816 [label="encoder.backbone_model.features.5.block.0.1.bias
 (120)" fillcolor=lightblue]
	139933850816816 -> 139934130650752
	139934130650752 [label=AccumulateGrad]
	139934130650656 -> 139934130650512
	139933850816336 [label="encoder.backbone_model.features.5.block.1.0.weight
 (120, 1, 5, 5)" fillcolor=lightblue]
	139933850816336 -> 139934130650656
	139934130650656 [label=AccumulateGrad]
	139934130650464 -> 139934130650416
	139933850816496 [label="encoder.backbone_model.features.5.block.1.1.weight
 (120)" fillcolor=lightblue]
	139933850816496 -> 139934130650464
	139934130650464 [label=AccumulateGrad]
	139934130650320 -> 139934130650416
	139933850816176 [label="encoder.backbone_model.features.5.block.1.1.bias
 (120)" fillcolor=lightblue]
	139933850816176 -> 139934130650320
	139934130650320 [label=AccumulateGrad]
	139934130650128 -> 139934130650080
	139933850815856 [label="encoder.backbone_model.features.5.block.2.fc1.weight
 (32, 120, 1, 1)" fillcolor=lightblue]
	139933850815856 -> 139934130650128
	139934130650128 [label=AccumulateGrad]
	139934130649984 -> 139934130650080
	139933850815696 [label="encoder.backbone_model.features.5.block.2.fc1.bias
 (32)" fillcolor=lightblue]
	139933850815696 -> 139934130649984
	139934130649984 [label=AccumulateGrad]
	139934130649840 -> 139934130649792
	139933850815616 [label="encoder.backbone_model.features.5.block.2.fc2.weight
 (120, 32, 1, 1)" fillcolor=lightblue]
	139933850815616 -> 139934130649840
	139934130649840 [label=AccumulateGrad]
	139934130649696 -> 139934130649792
	139933850815456 [label="encoder.backbone_model.features.5.block.2.fc2.bias
 (120)" fillcolor=lightblue]
	139933850815456 -> 139934130649696
	139934130649696 [label=AccumulateGrad]
	139934130647728 -> 139934130649552
	139934130649504 -> 139934130649360
	139933850815296 [label="encoder.backbone_model.features.5.block.3.0.weight
 (40, 120, 1, 1)" fillcolor=lightblue]
	139933850815296 -> 139934130649504
	139934130649504 [label=AccumulateGrad]
	139934130649216 -> 139934130648928
	139933850815376 [label="encoder.backbone_model.features.5.block.3.1.weight
 (40)" fillcolor=lightblue]
	139933850815376 -> 139934130649216
	139934130649216 [label=AccumulateGrad]
	139934130649072 -> 139934130648928
	139933850815216 [label="encoder.backbone_model.features.5.block.3.1.bias
 (40)" fillcolor=lightblue]
	139933850815216 -> 139934130649072
	139934130649072 [label=AccumulateGrad]
	139934130648784 -> 139934152252032
	139934130648640 -> 139934130648064
	139933850814736 [label="encoder.backbone_model.features.6.block.0.0.weight
 (120, 40, 1, 1)" fillcolor=lightblue]
	139933850814736 -> 139934130648640
	139934130648640 [label=AccumulateGrad]
	139934130647968 -> 139934130647872
	139933850814576 [label="encoder.backbone_model.features.6.block.0.1.weight
 (120)" fillcolor=lightblue]
	139933850814576 -> 139934130647968
	139934130647968 [label=AccumulateGrad]
	139934130647296 -> 139934130647872
	139933850814656 [label="encoder.backbone_model.features.6.block.0.1.bias
 (120)" fillcolor=lightblue]
	139933850814656 -> 139934130647296
	139934130647296 [label=AccumulateGrad]
	139934130639040 -> 139934130640384
	139933850814016 [label="encoder.backbone_model.features.6.block.1.0.weight
 (120, 1, 5, 5)" fillcolor=lightblue]
	139933850814016 -> 139934130639040
	139934130639040 [label=AccumulateGrad]
	139934130639136 -> 139934130639520
	139933850813936 [label="encoder.backbone_model.features.6.block.1.1.weight
 (120)" fillcolor=lightblue]
	139933850813936 -> 139934130639136
	139934130639136 [label=AccumulateGrad]
	139934130648112 -> 139934130639520
	139933850813856 [label="encoder.backbone_model.features.6.block.1.1.bias
 (120)" fillcolor=lightblue]
	139933850813856 -> 139934130648112
	139934130648112 [label=AccumulateGrad]
	139934130648016 -> 139934130646624
	139933850813616 [label="encoder.backbone_model.features.6.block.2.fc1.weight
 (32, 120, 1, 1)" fillcolor=lightblue]
	139933850813616 -> 139934130648016
	139934130648016 [label=AccumulateGrad]
	139934130637744 -> 139934130646624
	139933850813536 [label="encoder.backbone_model.features.6.block.2.fc1.bias
 (32)" fillcolor=lightblue]
	139933850813536 -> 139934130637744
	139934130637744 [label=AccumulateGrad]
	139934129864864 -> 139934129865536
	139933850813376 [label="encoder.backbone_model.features.6.block.2.fc2.weight
 (120, 32, 1, 1)" fillcolor=lightblue]
	139933850813376 -> 139934129864864
	139934129864864 [label=AccumulateGrad]
	139934129866160 -> 139934129865536
	139933850813296 [label="encoder.backbone_model.features.6.block.2.fc2.bias
 (120)" fillcolor=lightblue]
	139933850813296 -> 139934129866160
	139934129866160 [label=AccumulateGrad]
	139934129865344 -> 139934129873936
	139934129865152 -> 139934130138768
	139933850812976 [label="encoder.backbone_model.features.6.block.3.0.weight
 (40, 120, 1, 1)" fillcolor=lightblue]
	139933850812976 -> 139934129865152
	139934129865152 [label=AccumulateGrad]
	139934130135216 -> 139934130140784
	139933850813136 [label="encoder.backbone_model.features.6.block.3.1.weight
 (40)" fillcolor=lightblue]
	139933850813136 -> 139934130135216
	139934130135216 [label=AccumulateGrad]
	139934129873312 -> 139934130140784
	139933850812816 [label="encoder.backbone_model.features.6.block.3.1.bias
 (40)" fillcolor=lightblue]
	139933850812816 -> 139934129873312
	139934129873312 [label=AccumulateGrad]
	139934152252032 -> 139934129734656
	139934130139392 -> 139934129740464
	139934152013968 [label="encoder.backbone_model.features.7.block.0.0.weight
 (240, 40, 1, 1)" fillcolor=lightblue]
	139934152013968 -> 139934130139392
	139934130139392 [label=AccumulateGrad]
	139934129740224 -> 139934129740080
	139938495877904 [label="encoder.backbone_model.features.7.block.0.1.weight
 (240)" fillcolor=lightblue]
	139938495877904 -> 139934129740224
	139934129740224 [label=AccumulateGrad]
	139934129739456 -> 139934129740080
	139934152007008 [label="encoder.backbone_model.features.7.block.0.1.bias
 (240)" fillcolor=lightblue]
	139934152007008 -> 139934129739456
	139934129739456 [label=AccumulateGrad]
	139934129738976 -> 139934129738304
	139934129912832 [label="encoder.backbone_model.features.7.block.1.0.weight
 (240, 1, 3, 3)" fillcolor=lightblue]
	139934129912832 -> 139934129738976
	139934129738976 [label=AccumulateGrad]
	139934129749344 -> 139934129747760
	139934129900192 [label="encoder.backbone_model.features.7.block.1.1.weight
 (240)" fillcolor=lightblue]
	139934129900192 -> 139934129749344
	139934129749344 [label=AccumulateGrad]
	139934129747232 -> 139934129747760
	139934129909952 [label="encoder.backbone_model.features.7.block.1.1.bias
 (240)" fillcolor=lightblue]
	139934129909952 -> 139934129747232
	139934129747232 [label=AccumulateGrad]
	139934129741280 -> 139934129748000
	139934129910832 [label="encoder.backbone_model.features.7.block.2.0.weight
 (80, 240, 1, 1)" fillcolor=lightblue]
	139934129910832 -> 139934129741280
	139934129741280 [label=AccumulateGrad]
	139934129739168 -> 139934129747280
	139934129905312 [label="encoder.backbone_model.features.7.block.2.1.weight
 (80)" fillcolor=lightblue]
	139934129905312 -> 139934129739168
	139934129739168 [label=AccumulateGrad]
	139934129734224 -> 139934129747280
	139934129911632 [label="encoder.backbone_model.features.7.block.2.1.bias
 (80)" fillcolor=lightblue]
	139934129911632 -> 139934129734224
	139934129734224 [label=AccumulateGrad]
	139934129746800 -> 139934129747184
	139934129909792 [label="encoder.backbone_model.features.8.block.0.0.weight
 (200, 80, 1, 1)" fillcolor=lightblue]
	139934129909792 -> 139934129746800
	139934129746800 [label=AccumulateGrad]
	139934129741088 -> 139934129738064
	139934129907232 [label="encoder.backbone_model.features.8.block.0.1.weight
 (200)" fillcolor=lightblue]
	139934129907232 -> 139934129741088
	139934129741088 [label=AccumulateGrad]
	139934129745984 -> 139934129738064
	139934129909152 [label="encoder.backbone_model.features.8.block.0.1.bias
 (200)" fillcolor=lightblue]
	139934129909152 -> 139934129745984
	139934129745984 [label=AccumulateGrad]
	139934129745792 -> 139934129743440
	139934129904992 [label="encoder.backbone_model.features.8.block.1.0.weight
 (200, 1, 3, 3)" fillcolor=lightblue]
	139934129904992 -> 139934129745792
	139934129745792 [label=AccumulateGrad]
	139934129747424 -> 139934129745024
	139934129904752 [label="encoder.backbone_model.features.8.block.1.1.weight
 (200)" fillcolor=lightblue]
	139934129904752 -> 139934129747424
	139934129747424 [label=AccumulateGrad]
	139934129739648 -> 139934129745024
	139934129903472 [label="encoder.backbone_model.features.8.block.1.1.bias
 (200)" fillcolor=lightblue]
	139934129903472 -> 139934129739648
	139934129739648 [label=AccumulateGrad]
	139934129749056 -> 139934129748864
	139934129901632 [label="encoder.backbone_model.features.8.block.2.0.weight
 (80, 200, 1, 1)" fillcolor=lightblue]
	139934129901632 -> 139934129749056
	139934129749056 [label=AccumulateGrad]
	139934129748480 -> 139934129746176
	139934129898752 [label="encoder.backbone_model.features.8.block.2.1.weight
 (80)" fillcolor=lightblue]
	139934129898752 -> 139934129748480
	139934129748480 [label=AccumulateGrad]
	139934129748720 -> 139934129746176
	139934129900352 [label="encoder.backbone_model.features.8.block.2.1.bias
 (80)" fillcolor=lightblue]
	139934129900352 -> 139934129748720
	139934129748720 [label=AccumulateGrad]
	139934129747280 -> 139934129743488
	139934129747808 -> 139934129748576
	139934129913392 [label="encoder.backbone_model.features.9.block.0.0.weight
 (184, 80, 1, 1)" fillcolor=lightblue]
	139934129913392 -> 139934129747808
	139934129747808 [label=AccumulateGrad]
	139934129733936 -> 139934129740608
	139934129912592 [label="encoder.backbone_model.features.9.block.0.1.weight
 (184)" fillcolor=lightblue]
	139934129912592 -> 139934129733936
	139934129733936 [label=AccumulateGrad]
	139934129746608 -> 139934129740608
	139934129897712 [label="encoder.backbone_model.features.9.block.0.1.bias
 (184)" fillcolor=lightblue]
	139934129897712 -> 139934129746608
	139934129746608 [label=AccumulateGrad]
	139934129746368 -> 139934129748624
	139934151832624 [label="encoder.backbone_model.features.9.block.1.0.weight
 (184, 1, 3, 3)" fillcolor=lightblue]
	139934151832624 -> 139934129746368
	139934129746368 [label=AccumulateGrad]
	139934129742720 -> 139934129744352
	139934151827264 [label="encoder.backbone_model.features.9.block.1.1.weight
 (184)" fillcolor=lightblue]
	139934151827264 -> 139934129742720
	139934129742720 [label=AccumulateGrad]
	139934129744976 -> 139934129744352
	139934151826864 [label="encoder.backbone_model.features.9.block.1.1.bias
 (184)" fillcolor=lightblue]
	139934151826864 -> 139934129744976
	139934129744976 [label=AccumulateGrad]
	139934129744736 -> 139934129744592
	139934151827824 [label="encoder.backbone_model.features.9.block.2.0.weight
 (80, 184, 1, 1)" fillcolor=lightblue]
	139934151827824 -> 139934129744736
	139934129744736 [label=AccumulateGrad]
	139934129744064 -> 139934129743680
	139934151832544 [label="encoder.backbone_model.features.9.block.2.1.weight
 (80)" fillcolor=lightblue]
	139934151832544 -> 139934129744064
	139934129744064 [label=AccumulateGrad]
	139934129743872 -> 139934129743680
	139934151829984 [label="encoder.backbone_model.features.9.block.2.1.bias
 (80)" fillcolor=lightblue]
	139934151829984 -> 139934129743872
	139934129743872 [label=AccumulateGrad]
	139934129743488 -> 139934151911520
	139934129746080 -> 139934129742336
	139934130242176 [label="encoder.backbone_model.features.10.block.0.0.weight
 (184, 80, 1, 1)" fillcolor=lightblue]
	139934130242176 -> 139934129746080
	139934129746080 [label=AccumulateGrad]
	139934129742912 -> 139934129747040
	139934130245376 [label="encoder.backbone_model.features.10.block.0.1.weight
 (184)" fillcolor=lightblue]
	139934130245376 -> 139934129742912
	139934129742912 [label=AccumulateGrad]
	139934129740992 -> 139934129747040
	139934130251936 [label="encoder.backbone_model.features.10.block.0.1.bias
 (184)" fillcolor=lightblue]
	139934130251936 -> 139934129740992
	139934129740992 [label=AccumulateGrad]
	139934129741568 -> 139934129741952
	139934130257456 [label="encoder.backbone_model.features.10.block.1.0.weight
 (184, 1, 3, 3)" fillcolor=lightblue]
	139934130257456 -> 139934129741568
	139934129741568 [label=AccumulateGrad]
	139934129743248 -> 139938493169136
	139934130257536 [label="encoder.backbone_model.features.10.block.1.1.weight
 (184)" fillcolor=lightblue]
	139934130257536 -> 139934129743248
	139934129743248 [label=AccumulateGrad]
	139934129734800 -> 139938493169136
	139934130257376 [label="encoder.backbone_model.features.10.block.1.1.bias
 (184)" fillcolor=lightblue]
	139934130257376 -> 139934129734800
	139934129734800 [label=AccumulateGrad]
	139934151909888 -> 139934151911424
	139934130253056 [label="encoder.backbone_model.features.10.block.2.0.weight
 (80, 184, 1, 1)" fillcolor=lightblue]
	139934130253056 -> 139934151909888
	139934151909888 [label=AccumulateGrad]
	139934151908688 -> 139934151910032
	139934130256976 [label="encoder.backbone_model.features.10.block.2.1.weight
 (80)" fillcolor=lightblue]
	139934130256976 -> 139934151908688
	139934151908688 [label=AccumulateGrad]
	139934151911472 -> 139934151910032
	139934130257056 [label="encoder.backbone_model.features.10.block.2.1.bias
 (80)" fillcolor=lightblue]
	139934130257056 -> 139934151911472
	139934151911472 [label=AccumulateGrad]
	139934151911520 -> 139934151916416
	139934151916368 -> 139934151915984
	139934130256576 [label="encoder.backbone_model.features.11.block.0.0.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	139934130256576 -> 139934151916368
	139934151916368 [label=AccumulateGrad]
	139934151917040 -> 139934151915504
	139934130256736 [label="encoder.backbone_model.features.11.block.0.1.weight
 (480)" fillcolor=lightblue]
	139934130256736 -> 139934151917040
	139934151917040 [label=AccumulateGrad]
	139934151916320 -> 139934151915504
	139934130256496 [label="encoder.backbone_model.features.11.block.0.1.bias
 (480)" fillcolor=lightblue]
	139934130256496 -> 139934151916320
	139934151916320 [label=AccumulateGrad]
	139934151915456 -> 139934151916272
	139934130256016 [label="encoder.backbone_model.features.11.block.1.0.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	139934130256016 -> 139934151915456
	139934151915456 [label=AccumulateGrad]
	139934151916656 -> 139934151913776
	139934130256096 [label="encoder.backbone_model.features.11.block.1.1.weight
 (480)" fillcolor=lightblue]
	139934130256096 -> 139934151916656
	139934151916656 [label=AccumulateGrad]
	139934151914928 -> 139934151913776
	139934130255696 [label="encoder.backbone_model.features.11.block.1.1.bias
 (480)" fillcolor=lightblue]
	139934130255696 -> 139934151914928
	139934151914928 [label=AccumulateGrad]
	139934151915072 -> 139934151915024
	139934130255456 [label="encoder.backbone_model.features.11.block.2.fc1.weight
 (120, 480, 1, 1)" fillcolor=lightblue]
	139934130255456 -> 139934151915072
	139934151915072 [label=AccumulateGrad]
	139934151914112 -> 139934151915024
	139934130255296 [label="encoder.backbone_model.features.11.block.2.fc1.bias
 (120)" fillcolor=lightblue]
	139934130255296 -> 139934151914112
	139934151914112 [label=AccumulateGrad]
	139934151912192 -> 139934151913344
	139934130255216 [label="encoder.backbone_model.features.11.block.2.fc2.weight
 (480, 120, 1, 1)" fillcolor=lightblue]
	139934130255216 -> 139934151912192
	139934151912192 [label=AccumulateGrad]
	139934151914976 -> 139934151913344
	139934130255056 [label="encoder.backbone_model.features.11.block.2.fc2.bias
 (480)" fillcolor=lightblue]
	139934130255056 -> 139934151914976
	139934151914976 [label=AccumulateGrad]
	139934151913968 -> 139934151913728
	139934151914016 -> 139934151916032
	139934130250496 [label="encoder.backbone_model.features.11.block.3.0.weight
 (112, 480, 1, 1)" fillcolor=lightblue]
	139934130250496 -> 139934151914016
	139934151914016 [label=AccumulateGrad]
	139934151913152 -> 139934151913488
	139934130254976 [label="encoder.backbone_model.features.11.block.3.1.weight
 (112)" fillcolor=lightblue]
	139934130254976 -> 139934151913152
	139934151913152 [label=AccumulateGrad]
	139934151912432 -> 139934151913488
	139934130254896 [label="encoder.backbone_model.features.11.block.3.1.bias
 (112)" fillcolor=lightblue]
	139934130254896 -> 139934151912432
	139934151912432 [label=AccumulateGrad]
	139934151912720 -> 139934151912960
	139934130254496 [label="encoder.backbone_model.features.12.block.0.0.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	139934130254496 -> 139934151912720
	139934151912720 [label=AccumulateGrad]
	139934151913584 -> 139934151913248
	139934130254576 [label="encoder.backbone_model.features.12.block.0.1.weight
 (672)" fillcolor=lightblue]
	139934130254576 -> 139934151913584
	139934151913584 [label=AccumulateGrad]
	139934151912864 -> 139934151913248
	139934130254336 [label="encoder.backbone_model.features.12.block.0.1.bias
 (672)" fillcolor=lightblue]
	139934130254336 -> 139934151912864
	139934151912864 [label=AccumulateGrad]
	139934151912624 -> 139934151912240
	139934130253616 [label="encoder.backbone_model.features.12.block.1.0.weight
 (672, 1, 3, 3)" fillcolor=lightblue]
	139934130253616 -> 139934151912624
	139934151912624 [label=AccumulateGrad]
	139934151913440 -> 139934151912288
	139934130253296 [label="encoder.backbone_model.features.12.block.1.1.weight
 (672)" fillcolor=lightblue]
	139934130253296 -> 139934151913440
	139934151913440 [label=AccumulateGrad]
	139934151912384 -> 139934151912288
	139934130251456 [label="encoder.backbone_model.features.12.block.1.1.bias
 (672)" fillcolor=lightblue]
	139934130251456 -> 139934151912384
	139934151912384 [label=AccumulateGrad]
	139934151914496 -> 139934151908880
	139934130250896 [label="encoder.backbone_model.features.12.block.2.fc1.weight
 (168, 672, 1, 1)" fillcolor=lightblue]
	139934130250896 -> 139934151914496
	139934151914496 [label=AccumulateGrad]
	139934151911904 -> 139934151908880
	139934130251296 [label="encoder.backbone_model.features.12.block.2.fc1.bias
 (168)" fillcolor=lightblue]
	139934130251296 -> 139934151911904
	139934151911904 [label=AccumulateGrad]
	139934151913008 -> 139934151910656
	139934130250016 [label="encoder.backbone_model.features.12.block.2.fc2.weight
 (672, 168, 1, 1)" fillcolor=lightblue]
	139934130250016 -> 139934151913008
	139934151913008 [label=AccumulateGrad]
	139934151911280 -> 139934151910656
	139934130249136 [label="encoder.backbone_model.features.12.block.2.fc2.bias
 (672)" fillcolor=lightblue]
	139934130249136 -> 139934151911280
	139934151911280 [label=AccumulateGrad]
	139934151911712 -> 139934151910800
	139934151910896 -> 139934151911328
	139934130247936 [label="encoder.backbone_model.features.12.block.3.0.weight
 (112, 672, 1, 1)" fillcolor=lightblue]
	139934130247936 -> 139934151910896
	139934151910896 [label=AccumulateGrad]
	139934151911232 -> 139934151911088
	139934130248896 [label="encoder.backbone_model.features.12.block.3.1.weight
 (112)" fillcolor=lightblue]
	139934130248896 -> 139934151911232
	139934151911232 [label=AccumulateGrad]
	139934151911376 -> 139934151911088
	139934130248976 [label="encoder.backbone_model.features.12.block.3.1.bias
 (112)" fillcolor=lightblue]
	139934130248976 -> 139934151911376
	139934151911376 [label=AccumulateGrad]
	139934151913488 -> 139934151916464
	139934151916800 -> 139934151917424
	139934130247456 [label="encoder.backbone_model.features.13.block.0.0.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	139934130247456 -> 139934151916800
	139934151916800 [label=AccumulateGrad]
	139934151917376 -> 139934151911184
	139934130246736 [label="encoder.backbone_model.features.13.block.0.1.weight
 (672)" fillcolor=lightblue]
	139934130246736 -> 139934151917376
	139934151917376 [label=AccumulateGrad]
	139934151915888 -> 139934151911184
	139934130246976 [label="encoder.backbone_model.features.13.block.0.1.bias
 (672)" fillcolor=lightblue]
	139934130246976 -> 139934151915888
	139934151915888 [label=AccumulateGrad]
	139934151916848 -> 139934151916128
	139934130245296 [label="encoder.backbone_model.features.13.block.1.0.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	139934130245296 -> 139934151916848
	139934151916848 [label=AccumulateGrad]
	139934151917280 -> 139934151915360
	139934130246176 [label="encoder.backbone_model.features.13.block.1.1.weight
 (672)" fillcolor=lightblue]
	139934130246176 -> 139934151917280
	139934151917280 [label=AccumulateGrad]
	139934151910368 -> 139934151915360
	139934130244576 [label="encoder.backbone_model.features.13.block.1.1.bias
 (672)" fillcolor=lightblue]
	139934130244576 -> 139934151910368
	139934151910368 [label=AccumulateGrad]
	139934151917136 -> 139934339028912
	139934130244656 [label="encoder.backbone_model.features.13.block.2.fc1.weight
 (168, 672, 1, 1)" fillcolor=lightblue]
	139934130244656 -> 139934151917136
	139934151917136 [label=AccumulateGrad]
	139934151915840 -> 139934339028912
	139934130244416 [label="encoder.backbone_model.features.13.block.2.fc1.bias
 (168)" fillcolor=lightblue]
	139934130244416 -> 139934151915840
	139934151915840 [label=AccumulateGrad]
	139938491346624 -> 139938491341344
	139934130244016 [label="encoder.backbone_model.features.13.block.2.fc2.weight
 (672, 168, 1, 1)" fillcolor=lightblue]
	139934130244016 -> 139938491346624
	139938491346624 [label=AccumulateGrad]
	139938491341728 -> 139938491341344
	139934130244496 [label="encoder.backbone_model.features.13.block.2.fc2.bias
 (672)" fillcolor=lightblue]
	139934130244496 -> 139938491341728
	139938491341728 [label=AccumulateGrad]
	139934151759264 -> 139934152260528
	139934152261488 -> 139934152259712
	139934130243536 [label="encoder.backbone_model.features.13.block.3.0.weight
 (160, 672, 1, 1)" fillcolor=lightblue]
	139934130243536 -> 139934152261488
	139934152261488 [label=AccumulateGrad]
	139934152258656 -> 139934152256400
	139934130243136 [label="encoder.backbone_model.features.13.block.3.1.weight
 (160)" fillcolor=lightblue]
	139934130243136 -> 139934152258656
	139934152258656 [label=AccumulateGrad]
	139934152259856 -> 139934152256400
	139934130242416 [label="encoder.backbone_model.features.13.block.3.1.bias
 (160)" fillcolor=lightblue]
	139934130242416 -> 139934152259856
	139934152259856 [label=AccumulateGrad]
	139934152259664 -> 139934152257264
	139934130245536 [label="encoder.backbone_model.features.14.block.0.0.weight
 (960, 160, 1, 1)" fillcolor=lightblue]
	139934130245536 -> 139934152259664
	139934152259664 [label=AccumulateGrad]
	139934152257072 -> 139934152258560
	139934130241696 [label="encoder.backbone_model.features.14.block.0.1.weight
 (960)" fillcolor=lightblue]
	139934130241696 -> 139934152257072
	139934152257072 [label=AccumulateGrad]
	139934152258752 -> 139934152258560
	139934130242096 [label="encoder.backbone_model.features.14.block.0.1.bias
 (960)" fillcolor=lightblue]
	139934130242096 -> 139934152258752
	139934152258752 [label=AccumulateGrad]
	139934152256544 -> 139934152258080
	139934130244176 [label="encoder.backbone_model.features.14.block.1.0.weight
 (960, 1, 5, 5)" fillcolor=lightblue]
	139934130244176 -> 139934152256544
	139934152256544 [label=AccumulateGrad]
	139934152257312 -> 139934152257984
	139934130243776 [label="encoder.backbone_model.features.14.block.1.1.weight
 (960)" fillcolor=lightblue]
	139934130243776 -> 139934152257312
	139934152257312 [label=AccumulateGrad]
	139934152257888 -> 139934152257984
	139934130243936 [label="encoder.backbone_model.features.14.block.1.1.bias
 (960)" fillcolor=lightblue]
	139934130243936 -> 139934152257888
	139934152257888 [label=AccumulateGrad]
	139934152257120 -> 139934152257024
	139934130245936 [label="encoder.backbone_model.features.14.block.2.fc1.weight
 (240, 960, 1, 1)" fillcolor=lightblue]
	139934130245936 -> 139934152257120
	139934152257120 [label=AccumulateGrad]
	139934152252416 -> 139934152257024
	139934130245616 [label="encoder.backbone_model.features.14.block.2.fc1.bias
 (240)" fillcolor=lightblue]
	139934130245616 -> 139934152252416
	139934152252416 [label=AccumulateGrad]
	139934152256592 -> 139934152256784
	139934130246256 [label="encoder.backbone_model.features.14.block.2.fc2.weight
 (960, 240, 1, 1)" fillcolor=lightblue]
	139934130246256 -> 139934152256592
	139934152256592 [label=AccumulateGrad]
	139934152256976 -> 139934152256784
	139934130246336 [label="encoder.backbone_model.features.14.block.2.fc2.bias
 (960)" fillcolor=lightblue]
	139934130246336 -> 139934152256976
	139934152256976 [label=AccumulateGrad]
	139934152257168 -> 139934152256352
	139934152255824 -> 139934152255632
	139934130247136 [label="encoder.backbone_model.features.14.block.3.0.weight
 (160, 960, 1, 1)" fillcolor=lightblue]
	139934130247136 -> 139934152255824
	139934152255824 [label=AccumulateGrad]
	139934152256448 -> 139934152255104
	139934130246896 [label="encoder.backbone_model.features.14.block.3.1.weight
 (160)" fillcolor=lightblue]
	139934130246896 -> 139934152256448
	139934152256448 [label=AccumulateGrad]
	139934152255056 -> 139934152255104
	139934130247776 [label="encoder.backbone_model.features.14.block.3.1.bias
 (160)" fillcolor=lightblue]
	139934130247776 -> 139934152255056
	139934152255056 [label=AccumulateGrad]
	139934152256400 -> 139934152252896
	139934152256112 -> 139934152256832
	139934130249536 [label="encoder.backbone_model.features.15.block.0.0.weight
 (960, 160, 1, 1)" fillcolor=lightblue]
	139934130249536 -> 139934152256112
	139934152256112 [label=AccumulateGrad]
	139934152255872 -> 139934152255728
	139934130249056 [label="encoder.backbone_model.features.15.block.0.1.weight
 (960)" fillcolor=lightblue]
	139934130249056 -> 139934152255872
	139934152255872 [label=AccumulateGrad]
	139934152255920 -> 139934152255728
	139934130242736 [label="encoder.backbone_model.features.15.block.0.1.bias
 (960)" fillcolor=lightblue]
	139934130242736 -> 139934152255920
	139934152255920 [label=AccumulateGrad]
	139934152255776 -> 139934152254720
	139934130253936 [label="encoder.backbone_model.features.15.block.1.0.weight
 (960, 1, 5, 5)" fillcolor=lightblue]
	139934130253936 -> 139934152255776
	139934152255776 [label=AccumulateGrad]
	139934152255008 -> 139934152254960
	139934130251616 [label="encoder.backbone_model.features.15.block.1.1.weight
 (960)" fillcolor=lightblue]
	139934130251616 -> 139934152255008
	139934152255008 [label=AccumulateGrad]
	139934152254912 -> 139934152254960
	139934130252816 [label="encoder.backbone_model.features.15.block.1.1.bias
 (960)" fillcolor=lightblue]
	139934130252816 -> 139934152254912
	139934152254912 [label=AccumulateGrad]
	139934152254096 -> 139934152254816
	139934130241936 [label="encoder.backbone_model.features.15.block.2.fc1.weight
 (240, 960, 1, 1)" fillcolor=lightblue]
	139934130241936 -> 139934152254096
	139934152254096 [label=AccumulateGrad]
	139934152254624 -> 139934152254816
	139934130243856 [label="encoder.backbone_model.features.15.block.2.fc1.bias
 (240)" fillcolor=lightblue]
	139934130243856 -> 139934152254624
	139934152254624 [label=AccumulateGrad]
	139934152255248 -> 139934152254288
	139934130247216 [label="encoder.backbone_model.features.15.block.2.fc2.weight
 (960, 240, 1, 1)" fillcolor=lightblue]
	139934130247216 -> 139934152255248
	139934152255248 [label=AccumulateGrad]
	139934152254240 -> 139934152254288
	139934130244896 [label="encoder.backbone_model.features.15.block.2.fc2.bias
 (960)" fillcolor=lightblue]
	139934130244896 -> 139934152254240
	139934152254240 [label=AccumulateGrad]
	139934152254576 -> 139934152253280
	139934152253616 -> 139934152253520
	139934130243376 [label="encoder.backbone_model.features.15.block.3.0.weight
 (160, 960, 1, 1)" fillcolor=lightblue]
	139934130243376 -> 139934152253616
	139934152253616 [label=AccumulateGrad]
	139934152253808 -> 139934152253184
	139934130245856 [label="encoder.backbone_model.features.15.block.3.1.weight
 (160)" fillcolor=lightblue]
	139934130245856 -> 139934152253808
	139934152253808 [label=AccumulateGrad]
	139934152252656 -> 139934152253184
	139934130249856 [label="encoder.backbone_model.features.15.block.3.1.bias
 (160)" fillcolor=lightblue]
	139934130249856 -> 139934152252656
	139934152252656 [label=AccumulateGrad]
	139934152252896 -> 139934152253088
	139934152253136 -> 139934152252848
	139934130254016 [label="encoder.backbone_model.features.16.0.weight
 (960, 160, 1, 1)" fillcolor=lightblue]
	139934130254016 -> 139934152253136
	139934152253136 [label=AccumulateGrad]
	139934152252800 -> 139934152253472
	139934130249936 [label="encoder.backbone_model.features.16.1.weight
 (960)" fillcolor=lightblue]
	139934130249936 -> 139934152252800
	139934152252800 [label=AccumulateGrad]
	139934152252560 -> 139934152253472
	139934130244336 [label="encoder.backbone_model.features.16.1.bias
 (960)" fillcolor=lightblue]
	139934130244336 -> 139934152252560
	139934152252560 [label=AccumulateGrad]
	139934152252032 -> 139934152252272
	139934152259376 -> 139934152251648
	139933850893712 [label="decoder_blocks.0.conv1.weight
 (20, 1000, 3, 3)" fillcolor=lightblue]
	139933850893712 -> 139934152259376
	139934152259376 [label=AccumulateGrad]
	139934152251168 -> 139934152251648
	139933850893952 [label="decoder_blocks.0.conv1.bias
 (20)" fillcolor=lightblue]
	139933850893952 -> 139934152251168
	139934152251168 [label=AccumulateGrad]
	139934152251600 -> 139934152251840
	139933850893792 [label="decoder_blocks.0.bn1.weight
 (20)" fillcolor=lightblue]
	139933850893792 -> 139934152251600
	139934152251600 [label=AccumulateGrad]
	139934152248912 -> 139934152251840
	139933850894192 [label="decoder_blocks.0.bn1.bias
 (20)" fillcolor=lightblue]
	139933850894192 -> 139934152248912
	139934152248912 [label=AccumulateGrad]
	139934152251552 -> 139934152253760
	139933850893072 [label="decoder_blocks.0.conv2.weight
 (20, 20, 3, 3)" fillcolor=lightblue]
	139933850893072 -> 139934152251552
	139934152251552 [label=AccumulateGrad]
	139934152251792 -> 139934152253760
	139933850892752 [label="decoder_blocks.0.conv2.bias
 (20)" fillcolor=lightblue]
	139933850892752 -> 139934152251792
	139934152251792 [label=AccumulateGrad]
	139934152249728 -> 139934152250832
	139933850892912 [label="decoder_blocks.0.bn2.weight
 (20)" fillcolor=lightblue]
	139933850892912 -> 139934152249728
	139934152249728 [label=AccumulateGrad]
	139934152248960 -> 139934152250832
	139933850892832 [label="decoder_blocks.0.bn2.bias
 (20)" fillcolor=lightblue]
	139933850892832 -> 139934152248960
	139934152248960 [label=AccumulateGrad]
	139934152250016 -> 139934152250880
	139934152249440 -> 139934152249152
	139933850892432 [label="decoder_blocks.1.conv1.weight
 (16, 44, 3, 3)" fillcolor=lightblue]
	139933850892432 -> 139934152249440
	139934152249440 [label=AccumulateGrad]
	139934152249680 -> 139934152249152
	139933850892272 [label="decoder_blocks.1.conv1.bias
 (16)" fillcolor=lightblue]
	139933850892272 -> 139934152249680
	139934152249680 [label=AccumulateGrad]
	139934152259568 -> 139934152250160
	139933850892112 [label="decoder_blocks.1.bn1.weight
 (16)" fillcolor=lightblue]
	139933850892112 -> 139934152259568
	139934152259568 [label=AccumulateGrad]
	139934152249536 -> 139934152250160
	139933850892192 [label="decoder_blocks.1.bn1.bias
 (16)" fillcolor=lightblue]
	139933850892192 -> 139934152249536
	139934152249536 [label=AccumulateGrad]
	139934152246608 -> 139934152247424
	139933850891712 [label="decoder_blocks.1.conv2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139933850891712 -> 139934152246608
	139934152246608 [label=AccumulateGrad]
	139934152249104 -> 139934152247424
	139933850891392 [label="decoder_blocks.1.conv2.bias
 (16)" fillcolor=lightblue]
	139933850891392 -> 139934152249104
	139934152249104 [label=AccumulateGrad]
	139934152248336 -> 139934152248000
	139933850891552 [label="decoder_blocks.1.bn2.weight
 (16)" fillcolor=lightblue]
	139933850891552 -> 139934152248336
	139934152248336 [label=AccumulateGrad]
	139934152248720 -> 139934152248000
	139933850891472 [label="decoder_blocks.1.bn2.bias
 (16)" fillcolor=lightblue]
	139933850891472 -> 139934152248720
	139934152248720 [label=AccumulateGrad]
	139934152248240 -> 139934152249056
	139934152246656 -> 139934152246848
	139933850878192 [label="decoder_blocks.2.conv1.weight
 (16, 40, 3, 3)" fillcolor=lightblue]
	139933850878192 -> 139934152246656
	139934152246656 [label=AccumulateGrad]
	139934152247184 -> 139934152246848
	139933850878352 [label="decoder_blocks.2.conv1.bias
 (16)" fillcolor=lightblue]
	139933850878352 -> 139934152247184
	139934152247184 [label=AccumulateGrad]
	139934152248624 -> 139934152249584
	139933850878112 [label="decoder_blocks.2.bn1.weight
 (16)" fillcolor=lightblue]
	139933850878112 -> 139934152248624
	139934152248624 [label=AccumulateGrad]
	139934152250304 -> 139934152249584
	139933850878672 [label="decoder_blocks.2.bn1.bias
 (16)" fillcolor=lightblue]
	139933850878672 -> 139934152250304
	139934152250304 [label=AccumulateGrad]
	139934152246800 -> 139934152247136
	139933850879312 [label="decoder_blocks.2.conv2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139933850879312 -> 139934152246800
	139934152246800 [label=AccumulateGrad]
	139934152246128 -> 139934152247136
	139933850879712 [label="decoder_blocks.2.conv2.bias
 (16)" fillcolor=lightblue]
	139933850879712 -> 139934152246128
	139934152246128 [label=AccumulateGrad]
	139934152258704 -> 139934152245984
	139933850879472 [label="decoder_blocks.2.bn2.weight
 (16)" fillcolor=lightblue]
	139933850879472 -> 139934152258704
	139934152258704 [label=AccumulateGrad]
	139934152245888 -> 139934152245984
	139933850879632 [label="decoder_blocks.2.bn2.bias
 (16)" fillcolor=lightblue]
	139933850879632 -> 139934152245888
	139934152245888 [label=AccumulateGrad]
	139934152247040 -> 139934152245696
	139934152246464 -> 139934152246704
	139933850880272 [label="decoder_blocks.3.conv1.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	139933850880272 -> 139934152246464
	139934152246464 [label=AccumulateGrad]
	139934152245648 -> 139934152246704
	139933850880512 [label="decoder_blocks.3.conv1.bias
 (16)" fillcolor=lightblue]
	139933850880512 -> 139934152245648
	139934152245648 [label=AccumulateGrad]
	139934152246416 -> 139934152247088
	139933850880592 [label="decoder_blocks.3.bn1.weight
 (16)" fillcolor=lightblue]
	139933850880592 -> 139934152246416
	139934152246416 [label=AccumulateGrad]
	139934152258896 -> 139934152247088
	139933850880832 [label="decoder_blocks.3.bn1.bias
 (16)" fillcolor=lightblue]
	139933850880832 -> 139934152258896
	139934152258896 [label=AccumulateGrad]
	139934152247952 -> 139934152261344
	139933850881712 [label="decoder_blocks.3.conv2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139933850881712 -> 139934152247952
	139934152247952 [label=AccumulateGrad]
	139934152261152 -> 139934152261344
	139933850881472 [label="decoder_blocks.3.conv2.bias
 (16)" fillcolor=lightblue]
	139933850881472 -> 139934152261152
	139934152261152 [label=AccumulateGrad]
	139934152260720 -> 139934152258848
	139933850881632 [label="decoder_blocks.3.bn2.weight
 (16)" fillcolor=lightblue]
	139933850881632 -> 139934152260720
	139934152260720 [label=AccumulateGrad]
	139934152261200 -> 139934152258848
	139933850882032 [label="decoder_blocks.3.bn2.bias
 (16)" fillcolor=lightblue]
	139933850882032 -> 139934152261200
	139934152261200 [label=AccumulateGrad]
	139934152259808 -> 139934152260816
	139933850882512 [label="seg_head.weight
 (1, 16, 1, 1)" fillcolor=lightblue]
	139933850882512 -> 139934152259808
	139934152259808 [label=AccumulateGrad]
	139934152260624 -> 139934152260816
	139933850882592 [label="seg_head.bias
 (1)" fillcolor=lightblue]
	139933850882592 -> 139934152260624
	139934152260624 [label=AccumulateGrad]
	139934152260816 -> 139934129711904
}
